{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292d74d1",
   "metadata": {},
   "source": [
    "# pair50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c2e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e478a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_than_50=pd.read_csv(\"./raw_data/epitope_morethan_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9263bc56",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CDR3B</th>\n",
       "      <th>Epitope</th>\n",
       "      <th>antigen_species</th>\n",
       "      <th>TRBV</th>\n",
       "      <th>TRBJ</th>\n",
       "      <th>MHC</th>\n",
       "      <th>ID</th>\n",
       "      <th>database</th>\n",
       "      <th>vdjdb_score</th>\n",
       "      <th>CDR3B_length</th>\n",
       "      <th>Epitope_length</th>\n",
       "      <th>Epitope_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62462</td>\n",
       "      <td>CASRDLADTQYF</td>\n",
       "      <td>ALSKGVHFV</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>62462.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60996</td>\n",
       "      <td>CASGLAGDSYNEQFF</td>\n",
       "      <td>ALSKGVHFV</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>60996.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93996</td>\n",
       "      <td>CASSLMGGYNEQFF</td>\n",
       "      <td>ALSKGVHFV</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>93996.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94040</td>\n",
       "      <td>CASSLQGASSYEQYF</td>\n",
       "      <td>ALSKGVHFV</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>94040.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116654</td>\n",
       "      <td>CASSSSGTFNLYEQYF</td>\n",
       "      <td>ALSKGVHFV</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>116654.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45586</th>\n",
       "      <td>163884</td>\n",
       "      <td>CAISEGTLSSYNEQFF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>Human herpesvirus 4 (Epstein Barr virus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>163884.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45587</th>\n",
       "      <td>181726</td>\n",
       "      <td>CATSDGQDEQYF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>Human herpesvirus 4 (Epstein Barr virus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>181726.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45588</th>\n",
       "      <td>181734</td>\n",
       "      <td>CATSDLKTGGEYEQYF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>Human herpesvirus 4 (Epstein Barr virus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>181734.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45589</th>\n",
       "      <td>181844</td>\n",
       "      <td>CASTDLAGGLTDTQYF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>Human herpesvirus 4 (Epstein Barr virus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>181844.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45590</th>\n",
       "      <td>181742</td>\n",
       "      <td>CATSDLKTGHNEQFF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>Human herpesvirus 4 (Epstein Barr virus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>181742.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45591 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             CDR3B    Epitope  \\\n",
       "0           62462      CASRDLADTQYF  ALSKGVHFV   \n",
       "1           60996   CASGLAGDSYNEQFF  ALSKGVHFV   \n",
       "2           93996    CASSLMGGYNEQFF  ALSKGVHFV   \n",
       "3           94040   CASSLQGASSYEQYF  ALSKGVHFV   \n",
       "4          116654  CASSSSGTFNLYEQYF  ALSKGVHFV   \n",
       "...           ...               ...        ...   \n",
       "45586      163884  CAISEGTLSSYNEQFF  YVLDHLIVV   \n",
       "45587      181726      CATSDGQDEQYF  YVLDHLIVV   \n",
       "45588      181734  CATSDLKTGGEYEQYF  YVLDHLIVV   \n",
       "45589      181844  CASTDLAGGLTDTQYF  YVLDHLIVV   \n",
       "45590      181742   CATSDLKTGHNEQFF  YVLDHLIVV   \n",
       "\n",
       "                                antigen_species TRBV TRBJ          MHC  \\\n",
       "0                                     SARS-CoV2  NaN  NaN  HLA class I   \n",
       "1                                     SARS-CoV2  NaN  NaN  HLA class I   \n",
       "2                                     SARS-CoV2  NaN  NaN  HLA class I   \n",
       "3                                     SARS-CoV2  NaN  NaN  HLA class I   \n",
       "4                                     SARS-CoV2  NaN  NaN  HLA class I   \n",
       "...                                         ...  ...  ...          ...   \n",
       "45586  Human herpesvirus 4 (Epstein Barr virus)  NaN  NaN  HLA-A*02:01   \n",
       "45587  Human herpesvirus 4 (Epstein Barr virus)  NaN  NaN  HLA-A*02:01   \n",
       "45588  Human herpesvirus 4 (Epstein Barr virus)  NaN  NaN  HLA-A*02:01   \n",
       "45589  Human herpesvirus 4 (Epstein Barr virus)  NaN  NaN  HLA-A*02:01   \n",
       "45590  Human herpesvirus 4 (Epstein Barr virus)  NaN  NaN  HLA-A*02:01   \n",
       "\n",
       "             ID database  vdjdb_score  CDR3B_length  Epitope_length  \\\n",
       "0       62462.0     IEDB          NaN            12               9   \n",
       "1       60996.0     IEDB          NaN            15               9   \n",
       "2       93996.0     IEDB          NaN            14               9   \n",
       "3       94040.0     IEDB          NaN            15               9   \n",
       "4      116654.0     IEDB          NaN            16               9   \n",
       "...         ...      ...          ...           ...             ...   \n",
       "45586  163884.0     IEDB          NaN            16               9   \n",
       "45587  181726.0     IEDB          NaN            12               9   \n",
       "45588  181734.0     IEDB          NaN            16               9   \n",
       "45589  181844.0     IEDB          NaN            16               9   \n",
       "45590  181742.0     IEDB          NaN            15               9   \n",
       "\n",
       "       Epitope_Count  \n",
       "0                227  \n",
       "1                227  \n",
       "2                227  \n",
       "3                227  \n",
       "4                227  \n",
       "...              ...  \n",
       "45586           6766  \n",
       "45587           6766  \n",
       "45588           6766  \n",
       "45589           6766  \n",
       "45590           6766  \n",
       "\n",
       "[45591 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greater_than_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418c1e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(greater_than_50['Epitope']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0ffb1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1, test_df1 = train_test_split(greater_than_50, test_size=4559, stratify=greater_than_50[['Epitope']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f262c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.to_csv(\"./raw_data/pair50_repeat10/train1.csv\")\n",
    "test_df1.to_csv(\"./raw_data/pair50_repeat10/test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8fc3ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df2, test_df2 = train_test_split(train_df1, test_size=4559, stratify=train_df1[['Epitope']])\n",
    "train_df22 = pd.concat([train_df2, test_df1], axis=0)\n",
    "train_df22.to_csv(\"./raw_data/pair50_repeat10/train2.csv\")\n",
    "test_df2.to_csv(\"./raw_data/pair50_repeat10/test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "933d4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df3, test_df3 = train_test_split(train_df2, test_size=4559, stratify=train_df2[['Epitope']])\n",
    "train_df33 = pd.concat([train_df3,test_df1,test_df2], axis=0)\n",
    "train_df33.to_csv(\"./raw_data/pair50_repeat10/train3.csv\")\n",
    "test_df3.to_csv(\"./raw_data/pair50_repeat10/test3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5e9cf864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df4, test_df4 = train_test_split(train_df3, test_size=4559, stratify=train_df3[['Epitope']])\n",
    "train_df44 = pd.concat([train_df4,test_df1,test_df2,test_df3], axis=0)\n",
    "train_df44.to_csv(\"./raw_data/pair50_repeat10/train4.csv\")\n",
    "test_df4.to_csv(\"./raw_data/pair50_repeat10/test4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "06d6d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df5, test_df5 = train_test_split(train_df4, test_size=4559, stratify=train_df4[['Epitope']])\n",
    "train_df55 = pd.concat([train_df5,test_df1,test_df2,test_df3,test_df4], axis=0)\n",
    "train_df55.to_csv(\"./raw_data/pair50_repeat10/train5.csv\")\n",
    "test_df5.to_csv(\"./raw_data/pair50_repeat10/test5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6ed1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afce79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a5350e1",
   "metadata": {},
   "source": [
    "# 匹配阴性数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "143550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.getcwd()\n",
    "def outer_filter_negative_data(df,neg_tcr,ratio):\n",
    "    unique_epitopes = df['Epitope'].unique()\n",
    "    unique_tcrs = df['CDR3B'].unique()\n",
    "    conversion_df = df[['Epitope', 'CDR3B']]\n",
    "    positive_pairs = set([tuple(x) for x in conversion_df.to_numpy()])\n",
    "    epitope_dist = df['Epitope'].value_counts()\n",
    "    tcr_dist = df['CDR3B'].value_counts()\n",
    "    epitope_freq_array = [epitope_dist[peptide] / len(df) for peptide in unique_epitopes]\n",
    "    neg_pairs = set()\n",
    "    neg_tcr_df = neg_tcr\n",
    "    for i in range(len(unique_epitopes)):\n",
    "        pairs_to_generate = round(epitope_dist[unique_epitopes[i]] * ratio)\n",
    "        selected_tcrs = np.random.choice(neg_tcr_df['CDR3B'], size=pairs_to_generate, replace=False )\n",
    "        new_pairs = [(unique_epitopes[i], tcr) for tcr in selected_tcrs]\n",
    "        neg_pairs.update(new_pairs)\n",
    "    negative_data = pd.DataFrame(neg_pairs, columns=['Epitope', 'CDR3B'])\n",
    "    negative_data = negative_data.assign(Affinity=0)\n",
    "    #df['Affinity'] = 1\n",
    "    df.loc[:, 'Affinity'] = 1\n",
    "    df = pd.concat([df, negative_data])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def Matches_negative_datasets(train_df1,test_df1,neg,path):\n",
    "    df1_train=outer_filter_negative_data(train_df1,neg,1)\n",
    "    df1_test=outer_filter_negative_data(test_df1,neg,1)\n",
    "    df1_train.to_csv(path + \"1_1train.csv\")\n",
    "    df1_test.to_csv(path + \"1_1test.csv\")\n",
    "    df2_train=outer_filter_negative_data(train_df1,neg,2)\n",
    "    df2_test=outer_filter_negative_data(test_df1,neg,2)\n",
    "    df2_train.to_csv(path + \"1_2train.csv\")\n",
    "    df2_test.to_csv(path + \"1_2test.csv\")\n",
    "    df4_train=outer_filter_negative_data(train_df1,neg,4)\n",
    "    df4_test=outer_filter_negative_data(test_df1,neg,4)\n",
    "    df4_train.to_csv(path +\"1_4train.csv\")\n",
    "    df4_test.to_csv(path +\"1_4test.csv\")\n",
    "    df6_train=outer_filter_negative_data(train_df1,neg,6)\n",
    "    df6_test=outer_filter_negative_data(test_df1,neg,6)\n",
    "    df6_train.to_csv(path + \"1_6train.csv\")\n",
    "    df6_test.to_csv(path + \"1_6test.csv\")\n",
    "    df8_train=outer_filter_negative_data(train_df1,neg,8)\n",
    "    df8_test=outer_filter_negative_data(test_df1,neg,8)\n",
    "    df8_train.to_csv(path +\"1_8train.csv\")\n",
    "    df8_test.to_csv(path +\"1_8test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6f129",
   "metadata": {},
   "source": [
    "# Dean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7d5f25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Dean=pd.read_csv(\"./raw_data/all_Dean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b2abd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Dean=pd.read_csv(\"./raw_data/all_Dean.csv\")\n",
    "greater_than_50=pd.read_csv(\"./raw_data/epitope_morethan_50.csv\")\n",
    "raw_Dean = raw_Dean[(raw_Dean['CDR3B_length'].between(10, 18))]\n",
    "duplicates = raw_Dean[raw_Dean['CDR3B'].isin(greater_than_50['CDR3B'])]\n",
    "Dean = raw_Dean[~raw_Dean['CDR3B'].isin(duplicates['CDR3B'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4851add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair50\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair50/Dean/\"+i+'_'\n",
    "    datapath=\"./raw_data/pair50_repeat10/\"\n",
    "    train_df1=pd.read_csv(datapath+'train'+i+'.csv')\n",
    "    test_df1=pd.read_csv(datapath+'test'+i+'.csv')\n",
    "    neg=Dean\n",
    "    Matches_negative_datasets(train_df1,test_df1,neg,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bb3edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c178993a",
   "metadata": {},
   "source": [
    "# TCRdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2686822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_TCRdb=pd.read_csv(\"./raw_data/al_TCRdb.csv\")\n",
    "raw_TCRdb = raw_TCRdb[(raw_TCRdb['CDR3B_length'].between(10, 18))]\n",
    "duplicates = raw_TCRdb[raw_TCRdb['CDR3B'].isin(greater_than_50['CDR3B'])]\n",
    "TCRdb = raw_TCRdb[~raw_TCRdb['CDR3B'].isin(duplicates['CDR3B'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "fc4dea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair50\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair50/TCRdb/\"+i+'_'\n",
    "    datapath=\"./raw_data/pair50_repeat10/\"\n",
    "    train_df1=pd.read_csv(datapath+'train'+i+'.csv')\n",
    "    test_df1=pd.read_csv(datapath+'test'+i+'.csv')\n",
    "    neg=TCRdb\n",
    "    Matches_negative_datasets(train_df1,test_df1,neg,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4401f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "91371c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw300\n",
    "name=['1','2','3','4','5']\n",
    "pair=['raw300']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        path=\"./pair300/\"+j+'/'+'TCRdb'+'/'+i+'_'\n",
    "        train_df1=pd.read_csv(\"./raw_data/trian_morethan_300.csv\")\n",
    "        test_df1=pd.read_csv(\"./raw_data/test_morethan_300.csv\")\n",
    "        neg=TCRdb\n",
    "        Matches_negative_datasets(train_df1,test_df1,neg,path)\n",
    "        \n",
    "name=['1','2','3','4','5']\n",
    "pair=['raw300']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        path=\"./pair300/\"+j+'/'+'Dean'+'/'+i+'_'\n",
    "        train_df1=pd.read_csv(\"./raw_data/trian_morethan_300.csv\")\n",
    "        test_df1=pd.read_csv(\"./raw_data/test_morethan_300.csv\")\n",
    "        neg=Dean\n",
    "        Matches_negative_datasets(train_df1,test_df1,neg,path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9f056c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def Matches_negative_datasets(test_df1,neg,path):\n",
    "    df1_test=outer_filter_negative_data(test_df1,neg,1)\n",
    "    df1_test.to_csv(path + \"1_1Validation.csv\")\n",
    "    df2_test=outer_filter_negative_data(test_df1,neg,2)\n",
    "    df2_test.to_csv(path + \"1_2Validation.csv\")\n",
    "    df4_test=outer_filter_negative_data(test_df1,neg,4)\n",
    "    df4_test.to_csv(path +\"1_4Validation.csv\")\n",
    "    df6_test=outer_filter_negative_data(test_df1,neg,6)\n",
    "    df6_test.to_csv(path + \"1_6Validation.csv\")\n",
    "    df8_test=outer_filter_negative_data(test_df1,neg,8)\n",
    "    df8_test.to_csv(path +\"1_8Validation.csv\")\n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./Validation/Dean/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/Validation_McPAS.csv\")\n",
    "    neg=Dean\n",
    "    Matches_negative_datasets(test_df1,neg,path)\n",
    "    \n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./Validation/TCRdb/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/Validation_McPAS.csv\")\n",
    "    neg=TCRdb\n",
    "    Matches_negative_datasets(test_df1,neg,path)\n",
    "    \n",
    "#Validation\n",
    "def Matches_negative_datasets(test_df1,neg,path):\n",
    "    df1_test=outer_filter_negative_data(test_df1,neg,1)\n",
    "    df1_test.to_csv(path + \"1_1train.csv\")\n",
    "    df2_test=outer_filter_negative_data(test_df1,neg,2)\n",
    "    df2_test.to_csv(path + \"1_2train.csv\")\n",
    "    df4_test=outer_filter_negative_data(test_df1,neg,4)\n",
    "    df4_test.to_csv(path +\"1_4train.csv\")\n",
    "    df6_test=outer_filter_negative_data(test_df1,neg,6)\n",
    "    df6_test.to_csv(path + \"1_6train.csv\")\n",
    "    df8_test=outer_filter_negative_data(test_df1,neg,8)\n",
    "    df8_test.to_csv(path +\"1_8train.csv\")\n",
    "    \n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./Validation/Dean/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/epitope_morethan_50.csv\")\n",
    "    neg=Dean\n",
    "    Matches_negative_datasets(test_df1,neg,path)\n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./Validation/TCRdb/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/epitope_morethan_50.csv\")\n",
    "    neg=TCRdb\n",
    "    Matches_negative_datasets(test_df1,neg,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6be61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "79803f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unknow\n",
    "def Matches_negative_datasets(test_df1,neg,path):\n",
    "    df1_test=outer_filter_negative_data(test_df1,neg,1)\n",
    "    df1_test.to_csv(path + \"1_1test.csv\")\n",
    "    df2_test=outer_filter_negative_data(test_df1,neg,2)\n",
    "    df2_test.to_csv(path + \"1_2test.csv\")\n",
    "    df4_test=outer_filter_negative_data(test_df1,neg,4)\n",
    "    df4_test.to_csv(path +\"1_4test.csv\")\n",
    "    df6_test=outer_filter_negative_data(test_df1,neg,6)\n",
    "    df6_test.to_csv(path + \"1_6test.csv\")\n",
    "    df8_test=outer_filter_negative_data(test_df1,neg,8)\n",
    "    df8_test.to_csv(path +\"1_8test.csv\")\n",
    "    \n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./unknow/Dean/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/epitope_less_50.csv\")\n",
    "    neg=Dean\n",
    "    Matches_negative_datasets(test_df1,neg,path)\n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./unknow/TCRdb/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/epitope_less_50.csv\")\n",
    "    neg=TCRdb\n",
    "    Matches_negative_datasets(test_df1,neg,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e226311a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5252a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e8177a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair300\n",
    "def Matches_negative_datasets(train_df1,neg,path):\n",
    "    df1_test=outer_filter_negative_data(test_df1,neg,1)\n",
    "    df1_test.to_csv(path + \"1_1train.csv\")\n",
    "    df2_test=outer_filter_negative_data(test_df1,neg,2)\n",
    "    df2_test.to_csv(path + \"1_2train.csv\")\n",
    "    df4_test=outer_filter_negative_data(test_df1,neg,4)\n",
    "    df4_test.to_csv(path +\"1_4train.csv\")\n",
    "    df6_test=outer_filter_negative_data(test_df1,neg,6)\n",
    "    df6_test.to_csv(path + \"1_6train.csv\")\n",
    "    df8_test=outer_filter_negative_data(test_df1,neg,8)\n",
    "    df8_test.to_csv(path +\"1_8train.csv\")\n",
    "          \n",
    "name=['1','2','3','4','5']\n",
    "pair=['300']\n",
    "data=['sampled300']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'TCRdb'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=TCRdb\n",
    "            Matches_negative_datasets(train_df1,neg,path) \n",
    "            \n",
    "name=['1','2','3','4','5']\n",
    "pair=['200']\n",
    "data=['sampled200']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'TCRdb'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=TCRdb\n",
    "            Matches_negative_datasets(train_df1,neg,path) \n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "pair=['100']\n",
    "data=['sampled100']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'TCRdb'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=TCRdb\n",
    "            Matches_negative_datasets(train_df1,neg,path) \n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "pair=['10']\n",
    "data=['sampled10']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'TCRdb'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=TCRdb\n",
    "            Matches_negative_datasets(train_df1,neg,path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "365bcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair300\n",
    "name=['1','2','3','4','5']\n",
    "pair=['300']\n",
    "data=['sampled300']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'Dean'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=Dean\n",
    "            Matches_negative_datasets(train_df1,neg,path)    \n",
    "            \n",
    "            \n",
    "name=['1','2','3','4','5']\n",
    "pair=['200']\n",
    "data=['sampled200']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'Dean'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=Dean\n",
    "            Matches_negative_datasets(train_df1,neg,path)   \n",
    "            \n",
    "            \n",
    "            \n",
    "name=['1','2','3','4','5']\n",
    "pair=['100']\n",
    "data=['sampled100']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'Dean'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=Dean\n",
    "            Matches_negative_datasets(train_df1,neg,path) \n",
    "            \n",
    "name=['1','2','3','4','5']\n",
    "pair=['10']\n",
    "data=['sampled10']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        for k in data:\n",
    "            path=\"./pair300/\"+j+'/'+'Dean'+'/'+i+'_'\n",
    "            train_df1=pd.read_csv(\"./raw_data/\"+k+\".csv\")\n",
    "            neg=Dean\n",
    "            Matches_negative_datasets(train_df1,neg,path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445532a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999ba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8386a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52fd0d09",
   "metadata": {},
   "source": [
    "# inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "12a52433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_data(df,ratio):\n",
    "    def random_recombination(df, epitope_dist, tcr_dist, ratio):\n",
    "        unique_epitopes = df['Epitope'].unique()\n",
    "        unique_tcrs = df['CDR3B'].unique()\n",
    "        conversion_df = df[['Epitope', 'CDR3B']]\n",
    "        positive_pairs = set([tuple(x) for x in conversion_df.to_numpy()])\n",
    "        epitope_freq_array = [epitope_dist[peptide] / len(df) for peptide in unique_epitopes]\n",
    "        tcr_freq_array = [tcr_dist[tcr] / len(df) for tcr in unique_tcrs]    \n",
    "        neg_pairs = set()\n",
    "        for pep in unique_epitopes:\n",
    "            i = 0\n",
    "            pairs_to_generate = round(epitope_dist[pep] * ratio)\n",
    "            while i < pairs_to_generate:\n",
    "                tcr = np.random.choice(unique_tcrs, p=tcr_freq_array)\n",
    "                pair = (pep, tcr)\n",
    "                if pair not in positive_pairs and pair not in neg_pairs:\n",
    "                    neg_pairs.add(pair)\n",
    "                    i += 1        \n",
    "        negative_data = pd.DataFrame(neg_pairs, columns = ['Epitope', 'CDR3B'])\n",
    "        negative_data = negative_data.assign(Affinity=0)\n",
    "        return negative_data\n",
    "    df.loc[:, 'Affinity'] = 1\n",
    "    epitope_distribution = df['Epitope'].value_counts()\n",
    "    tcr_distribution = df['CDR3B'].value_counts()\n",
    "    negative_data = random_recombination(df, epitope_distribution, tcr_distribution, ratio)\n",
    "    df = pd.concat([df, negative_data])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def inner_neg(train_df1,test_df1,path):\n",
    "    df1_train=negative_data(train_df1,1)\n",
    "    df1_test=negative_data(test_df1,1)\n",
    "    df1_train.to_csv(path + \"1_1train.csv\")\n",
    "    df1_test.to_csv(path + \"1_1test.csv\")\n",
    "    df2_train=negative_data(train_df1,2)\n",
    "    df2_test=negative_data(test_df1,2)\n",
    "    df2_train.to_csv(path + \"1_2train.csv\")\n",
    "    df2_test.to_csv(path + \"1_2test.csv\")\n",
    "    df4_train=negative_data(train_df1,4)\n",
    "    df4_test=negative_data(test_df1,4)\n",
    "    df4_train.to_csv(path +\"1_4train.csv\")\n",
    "    df4_test.to_csv(path +\"1_4test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "08ad12ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#par50\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair50/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/pair50_repeat10/test\"+i+'.csv')\n",
    "    train_df1=pd.read_csv(\"./raw_data/pair50_repeat10/train\"+i+'.csv')\n",
    "    inner_neg(train_df1,test_df1,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "26f258b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair300 raw300\n",
    "name=['1','2','3','4','5']\n",
    "pair=['raw300']\n",
    "for i in name:\n",
    "    for j in pair:\n",
    "        path=\"./pair300/raw300/inner/\"+i+'_'\n",
    "        train_df1=pd.read_csv(\"./raw_data/trian_morethan_300.csv\")\n",
    "        test_df1=pd.read_csv(\"./raw_data/test_morethan_300.csv\")\n",
    "        inner_neg(train_df1,test_df1,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d7eda978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def negative_data(df,ratio):\n",
    "    def random_recombination(df, epitope_dist, tcr_dist, ratio):\n",
    "        unique_epitopes = df['Epitope'].unique()\n",
    "        unique_tcrs = df['CDR3B'].unique()\n",
    "        conversion_df = df[['Epitope', 'CDR3B']]\n",
    "        positive_pairs = set([tuple(x) for x in conversion_df.to_numpy()])\n",
    "        epitope_freq_array = [epitope_dist[peptide] / len(df) for peptide in unique_epitopes]\n",
    "        tcr_freq_array = [tcr_dist[tcr] / len(df) for tcr in unique_tcrs]    \n",
    "        neg_pairs = set()\n",
    "        for pep in unique_epitopes:\n",
    "            i = 0\n",
    "            pairs_to_generate = round(epitope_dist[pep] * ratio)\n",
    "            while i < pairs_to_generate:\n",
    "                tcr = np.random.choice(unique_tcrs, p=tcr_freq_array)\n",
    "                pair = (pep, tcr)\n",
    "                if pair not in positive_pairs and pair not in neg_pairs:\n",
    "                    neg_pairs.add(pair)\n",
    "                    i += 1        \n",
    "        negative_data = pd.DataFrame(neg_pairs, columns = ['Epitope', 'CDR3B'])\n",
    "        negative_data = negative_data.assign(Affinity=0)\n",
    "        return negative_data\n",
    "    df.loc[:, 'Affinity'] = 1\n",
    "    epitope_distribution = df['Epitope'].value_counts()\n",
    "    tcr_distribution = df['CDR3B'].value_counts()\n",
    "    negative_data = random_recombination(df, epitope_distribution, tcr_distribution, ratio)\n",
    "    df = pd.concat([df, negative_data])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def inner_neg(train_df1,test_df1,path):\n",
    "    df1_train=negative_data(train_df1,1)\n",
    "    df1_test=negative_data(test_df1,1)\n",
    "    df1_train.to_csv(path + \"1_1train.csv\")\n",
    "    df1_test.to_csv(path + \"1_1Validation.csv\")\n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./Validation/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/Intersection_dataset/raw_data/Validation_McPAS.csv\")\n",
    "    train_df1=pd.read_csv(\"./raw_data/epitope_morethan_50.csv\")\n",
    "    inner_neg(train_df1,test_df1,path)\n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e7f88838",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair 300 300-10\n",
    "def inner_neg(test_df1,path):\n",
    "    df1_test=negative_data(test_df1,1)\n",
    "    df1_test.to_csv(path + \"1_1train.csv\")\n",
    "    df2_test=negative_data(test_df1,2)\n",
    "    df2_test.to_csv(path + \"1_2train.csv\")\n",
    "    df4_test=negative_data(test_df1,4)\n",
    "    df4_test.to_csv(path +\"1_4train.csv\")\n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair300/300/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/sampled300.csv\")\n",
    "    inner_neg(test_df1,path)\n",
    "    \n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair300/200/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/sampled200.csv\")\n",
    "    inner_neg(test_df1,path)\n",
    "    \n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair300/100/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/sampled100.csv\")\n",
    "    inner_neg(test_df1,path)\n",
    "    \n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./pair300/10/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/sampled10.csv\")\n",
    "    inner_neg(test_df1,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3f6e04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unknow\n",
    "def inner_neg(test_df1,path):\n",
    "    df1_test=negative_data(test_df1,1)\n",
    "    df1_test.to_csv(path + \"1_1test.csv\")\n",
    "    df2_test=negative_data(test_df1,2)\n",
    "    df2_test.to_csv(path + \"1_2test.csv\")\n",
    "    df4_test=negative_data(test_df1,4)\n",
    "    df4_test.to_csv(path +\"1_4test.csv\")\n",
    "\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./unknow/inner/\"+i+'_'\n",
    "    test_df1=pd.read_csv(\"./raw_data/epitope_less_50.csv\")\n",
    "    inner_neg(test_df1,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f56122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a6c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d4bb2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_neg(train_df1,path):\n",
    "    df2_train=negative_data(train_df1,2)\n",
    "    df2_train.to_csv(path + \"1_2train.csv\")\n",
    "    df4_train=negative_data(train_df1,4)\n",
    "    df4_train.to_csv(path +\"1_4train.csv\")\n",
    "name=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    path=\"./Validation/inner/\"+i+'_'\n",
    "    train_df1=pd.read_csv(\"./raw_data/epitope_morethan_50.csv\")\n",
    "    inner_neg(train_df1,path)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbd0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe643a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4845196",
   "metadata": {},
   "source": [
    "# unknown  validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba24a307",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/tmp/ipykernel_6274/121523937.py:12: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CDR3B</th>\n",
       "      <th>Epitope</th>\n",
       "      <th>antigen_species</th>\n",
       "      <th>TRBV</th>\n",
       "      <th>TRBJ</th>\n",
       "      <th>MHC</th>\n",
       "      <th>ID</th>\n",
       "      <th>database</th>\n",
       "      <th>vdjdb_score</th>\n",
       "      <th>CDR3B_length</th>\n",
       "      <th>Epitope_length</th>\n",
       "      <th>Epitope_Count</th>\n",
       "      <th>Affinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43230.0</td>\n",
       "      <td>187945.0</td>\n",
       "      <td>CSVGLVYTGELFF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>Human herpesvirus 4 (Epstein Barr virus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>187945.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6766.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6452.0</td>\n",
       "      <td>67270.0</td>\n",
       "      <td>CASRVAGGLLHEQYF</td>\n",
       "      <td>FPPTSFGPL</td>\n",
       "      <td>SARS-CoV1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>67270.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5059.0</td>\n",
       "      <td>89855.0</td>\n",
       "      <td>CASSLGGGSQETQYF</td>\n",
       "      <td>FLPRVFSAV</td>\n",
       "      <td>SARS-CoV2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA class I</td>\n",
       "      <td>89855.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20858.0</td>\n",
       "      <td>53025.0</td>\n",
       "      <td>CASSFNFREHTDTQYF</td>\n",
       "      <td>KLGGALQAK</td>\n",
       "      <td>Human herpesvirus 5 (Human cytomegalovirus)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HLA-A*03:01</td>\n",
       "      <td>53025.0</td>\n",
       "      <td>IEDB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4465.0</td>\n",
       "      <td>22615.0</td>\n",
       "      <td>CASSHGPGTGELFF</td>\n",
       "      <td>FLNGSCGSV</td>\n",
       "      <td>SARS-CoV-2</td>\n",
       "      <td>TRBV04-01</td>\n",
       "      <td>TRBJ02-02</td>\n",
       "      <td>MHCI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3880.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719915</th>\n",
       "      <td>123091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASSIYGAGYTEAFF</td>\n",
       "      <td>MPASWVMRI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719916</th>\n",
       "      <td>123092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CSADETGGQETQYF</td>\n",
       "      <td>IQYIDIGNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719917</th>\n",
       "      <td>123093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASRLAEGNNEQYF</td>\n",
       "      <td>GLCTLVAML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719918</th>\n",
       "      <td>123094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASSPQRGQSNTGELFF</td>\n",
       "      <td>YVLDHLIVV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719919</th>\n",
       "      <td>123095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CACSFPRGISYYEQFF</td>\n",
       "      <td>VLWAHGFEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12719920 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0              CDR3B  \\\n",
       "0                    0       43230.0    187945.0      CSVGLVYTGELFF   \n",
       "1                    1        6452.0     67270.0    CASRVAGGLLHEQYF   \n",
       "2                    2        5059.0     89855.0    CASSLGGGSQETQYF   \n",
       "3                    3       20858.0     53025.0   CASSFNFREHTDTQYF   \n",
       "4                    4        4465.0     22615.0     CASSHGPGTGELFF   \n",
       "...                ...           ...         ...                ...   \n",
       "12719915        123091           NaN         NaN    CASSIYGAGYTEAFF   \n",
       "12719916        123092           NaN         NaN     CSADETGGQETQYF   \n",
       "12719917        123093           NaN         NaN     CASRLAEGNNEQYF   \n",
       "12719918        123094           NaN         NaN  CASSPQRGQSNTGELFF   \n",
       "12719919        123095           NaN         NaN   CACSFPRGISYYEQFF   \n",
       "\n",
       "            Epitope                              antigen_species       TRBV  \\\n",
       "0         YVLDHLIVV     Human herpesvirus 4 (Epstein Barr virus)        NaN   \n",
       "1         FPPTSFGPL                                    SARS-CoV1        NaN   \n",
       "2         FLPRVFSAV                                    SARS-CoV2        NaN   \n",
       "3         KLGGALQAK  Human herpesvirus 5 (Human cytomegalovirus)        NaN   \n",
       "4         FLNGSCGSV                                   SARS-CoV-2  TRBV04-01   \n",
       "...             ...                                          ...        ...   \n",
       "12719915  MPASWVMRI                                          NaN        NaN   \n",
       "12719916  IQYIDIGNY                                          NaN        NaN   \n",
       "12719917  GLCTLVAML                                          NaN        NaN   \n",
       "12719918  YVLDHLIVV                                          NaN        NaN   \n",
       "12719919  VLWAHGFEL                                          NaN        NaN   \n",
       "\n",
       "               TRBJ          MHC        ID database  vdjdb_score  \\\n",
       "0               NaN  HLA-A*02:01  187945.0     IEDB          NaN   \n",
       "1               NaN  HLA class I   67270.0     IEDB          NaN   \n",
       "2               NaN  HLA class I   89855.0     IEDB          NaN   \n",
       "3               NaN  HLA-A*03:01   53025.0     IEDB          NaN   \n",
       "4         TRBJ02-02         MHCI       NaN     MIRA          NaN   \n",
       "...             ...          ...       ...      ...          ...   \n",
       "12719915        NaN          NaN       NaN      NaN          NaN   \n",
       "12719916        NaN          NaN       NaN      NaN          NaN   \n",
       "12719917        NaN          NaN       NaN      NaN          NaN   \n",
       "12719918        NaN          NaN       NaN      NaN          NaN   \n",
       "12719919        NaN          NaN       NaN      NaN          NaN   \n",
       "\n",
       "          CDR3B_length  Epitope_length  Epitope_Count  Affinity  \n",
       "0                 13.0             9.0         6766.0         1  \n",
       "1                 15.0             9.0          673.0         1  \n",
       "2                 15.0             9.0         1348.0         1  \n",
       "3                 16.0             9.0         1564.0         1  \n",
       "4                 14.0             9.0         3880.0         1  \n",
       "...                ...             ...            ...       ...  \n",
       "12719915           NaN             NaN            NaN         0  \n",
       "12719916           NaN             NaN            NaN         0  \n",
       "12719917           NaN             NaN            NaN         0  \n",
       "12719918           NaN             NaN            NaN         0  \n",
       "12719919           NaN             NaN            NaN         0  \n",
       "\n",
       "[12719920 rows x 16 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "paths = [\n",
    "    \"/pair50/patient/\",\n",
    "   \"/pair50/healthy/\",\n",
    "   \"/pair50/Antigen_specificity/\"]\n",
    "df_list = []\n",
    "for path in paths:\n",
    "    csv_files = glob.glob(os.path.join(path, \"*train*.csv\"))\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "merged_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bb250f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pos=pd.read_csv(\"./raw_data/unkown_validaiton.csv\")\n",
    "pos = pos[~pos['CDR3B'].isin(merged_df['CDR3B'])]\n",
    "pos = pos.drop_duplicates(subset=['CDR3B', 'Epitope'])\n",
    "pos.to_csv(\"./raw_data/unkown_validaiton.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "723bf059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.getcwd()\n",
    "def outer_filter_negative_data(df,neg_tcr,ratio):\n",
    "    unique_epitopes = df['Epitope'].unique()\n",
    "    unique_tcrs = df['CDR3B'].unique()\n",
    "    conversion_df = df[['Epitope', 'CDR3B']]\n",
    "    positive_pairs = set([tuple(x) for x in conversion_df.to_numpy()])\n",
    "    epitope_dist = df['Epitope'].value_counts()\n",
    "    tcr_dist = df['CDR3B'].value_counts()\n",
    "    epitope_freq_array = [epitope_dist[peptide] / len(df) for peptide in unique_epitopes]\n",
    "    neg_pairs = set()\n",
    "    neg_tcr_df = neg_tcr\n",
    "    for i in range(len(unique_epitopes)):\n",
    "        pairs_to_generate = round(epitope_dist[unique_epitopes[i]] * ratio)\n",
    "        selected_tcrs = np.random.choice(neg_tcr_df['CDR3B'], size=pairs_to_generate, replace=False )\n",
    "        new_pairs = [(unique_epitopes[i], tcr) for tcr in selected_tcrs]\n",
    "        neg_pairs.update(new_pairs)\n",
    "    negative_data = pd.DataFrame(neg_pairs, columns=['Epitope', 'CDR3B'])\n",
    "    negative_data = negative_data.assign(Affinity=0)\n",
    "    #df['Affinity'] = 1\n",
    "    df.loc[:, 'Affinity'] = 1\n",
    "    df = pd.concat([df, negative_data])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e08ea",
   "metadata": {},
   "source": [
    "# healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91a80fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Dean=pd.read_csv(\"./raw_data/all_Dean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "818f8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Dean=pd.read_csv(\"./raw_data/all_Dean.csv\")\n",
    "raw_Dean = raw_Dean[(raw_Dean['CDR3B_length'].between(10, 18))]\n",
    "duplicates = raw_Dean[raw_Dean['CDR3B'].isin(merged_df['CDR3B'])]\n",
    "Dean = raw_Dean[~raw_Dean['CDR3B'].isin(duplicates['CDR3B'])]\n",
    "Dean = Dean[~Dean['CDR3B'].isin(pos['CDR3B'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "823ef5d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "base_path = \"/unknow/validation/healthy/\"\n",
    "for i in range(1, 6):\n",
    "    df = outer_filter_negative_data(pos,Dean,1)\n",
    "    file_name = f\"{i}_1_1validation.csv\"\n",
    "    df.to_csv(os.path.join(base_path, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f708950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be6aff95",
   "metadata": {},
   "source": [
    "# patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8fa8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_TCRdb=pd.read_csv(\"./raw_data/al_TCRdb.csv\")\n",
    "raw_TCRdb = raw_TCRdb[(raw_TCRdb['CDR3B_length'].between(10, 18))]\n",
    "duplicates = raw_TCRdb[raw_TCRdb['CDR3B'].isin(merged_df['CDR3B'])]\n",
    "TCRdb = raw_TCRdb[~raw_TCRdb['CDR3B'].isin(duplicates['CDR3B'])]\n",
    "TCRdb = TCRdb[~TCRdb['CDR3B'].isin(pos['CDR3B'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2af75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = \"/unknow/validation/patient/\"\n",
    "for i in range(1, 6):\n",
    "    df = outer_filter_negative_data(pos,TCRdb,1)\n",
    "    file_name = f\"{i}_1_1validation.csv\"\n",
    "    df.to_csv(os.path.join(base_path, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa60a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1008644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1723ae5",
   "metadata": {},
   "source": [
    "# Antigen_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6da036c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_data(df,ratio):\n",
    "    def random_recombination(df, epitope_dist, tcr_dist, ratio):\n",
    "        unique_epitopes = df['Epitope'].unique()\n",
    "        unique_tcrs = df['CDR3B'].unique()\n",
    "        conversion_df = df[['Epitope', 'CDR3B']]\n",
    "        positive_pairs = set([tuple(x) for x in conversion_df.to_numpy()])\n",
    "        epitope_freq_array = [epitope_dist[peptide] / len(df) for peptide in unique_epitopes]\n",
    "        tcr_freq_array = [tcr_dist[tcr] / len(df) for tcr in unique_tcrs]    \n",
    "        neg_pairs = set()\n",
    "        for pep in unique_epitopes:\n",
    "            i = 0\n",
    "            pairs_to_generate = round(epitope_dist[pep] * ratio)\n",
    "            while i < pairs_to_generate:\n",
    "                tcr = np.random.choice(unique_tcrs, p=tcr_freq_array)\n",
    "                pair = (pep, tcr)\n",
    "                if pair not in positive_pairs and pair not in neg_pairs:\n",
    "                    neg_pairs.add(pair)\n",
    "                    i += 1        \n",
    "        negative_data = pd.DataFrame(neg_pairs, columns = ['Epitope', 'CDR3B'])\n",
    "        negative_data = negative_data.assign(Affinity=0)\n",
    "        return negative_data\n",
    "    df.loc[:, 'Affinity'] = 1\n",
    "    epitope_distribution = df['Epitope'].value_counts()\n",
    "    tcr_distribution = df['CDR3B'].value_counts()\n",
    "    negative_data = random_recombination(df, epitope_distribution, tcr_distribution, ratio)\n",
    "    df = pd.concat([df, negative_data])\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "155b3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "base_path = \"/unknow/validation/Antigen_specificity/\"\n",
    "for i in range(1, 6):\n",
    "    df1 = negative_data(pos, 1)\n",
    "    file_name = f\"{i}_1_1validation.csv\"\n",
    "    df1.to_csv(os.path.join(base_path, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678413e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113657cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53111349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc3a16be",
   "metadata": {},
   "source": [
    "# time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8073ee4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49148/181880034.py:3: DtypeWarning: Columns (5,6,7,8,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv(\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/pair50/healthy/1_1_1train.csv\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"/pair50/healthy/1_1_1train.csv\")\n",
    "subset_lengths  = [1000,5000,  10000, 100000, 1000000]\n",
    "df_sorted = data.sort_values(by='Epitope').reset_index(drop=True)\n",
    "df_sorted['Affinity'] = (df_sorted.index % 2).astype(int)\n",
    "subsets = []\n",
    "\n",
    "for length in subset_lengths:\n",
    "    if length <= len(df_sorted):\n",
    "        subset = df_sorted.head(length)\n",
    "    else:\n",
    "        subset = pd.concat([df_sorted] * (length // len(df_sorted) + 1))\n",
    "        subset = subset.head(length)\n",
    "    \n",
    "    subsets.append(subset)\n",
    "\n",
    "for i, subset in enumerate(subsets):\n",
    "    subset.to_csv(f'./time1/data_{subset_lengths[i]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c875c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
