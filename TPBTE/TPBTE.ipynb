{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fcffa3",
   "metadata": {},
   "source": [
    "# Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d934fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tpbte import Model\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "def data_renew(pairs, emb_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if emb_type == 'onehot':\n",
    "        tcr = pairs[:, :, 0:21].type(torch.LongTensor).to(device)\n",
    "        epi = pairs[:, :, 21:-1].type(torch.LongTensor).to(device)\n",
    "    elif emb_type == 'BLOSUM62':\n",
    "        tcr = pairs[:, :, 0:20].to(device)\n",
    "        epi = pairs[:, :, 20:].to(device)\n",
    "    else:\n",
    "        tcr = pairs[:, :, 0:5].to(device)\n",
    "        epi = pairs[:, :, 5:].to(device)\n",
    "    return tcr, epi\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, emb_type):\n",
    "\n",
    "        self.data = pd.read_csv(path,low_memory=False)\n",
    "        self.CDR3B = self.data['CDR3B']\n",
    "        self.Epitope = self.data['Epitope']\n",
    "        self.Affinity = self.data['Affinity']\n",
    "        self.emb_type = emb_type\n",
    "        if self.emb_type == 'onehot':\n",
    "            CDR3B, Epi, self.Affinity = onehot(self.CDR3B, self.Epitope, self.Affinity)\n",
    "        elif self.emb_type == 'BLOSUM62':\n",
    "            CDR3B, Epi, self.Affinity = BLOSUM_62(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        else:\n",
    "            CDR3B, Epi, self.Affinity = Atchley(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        self.pair = torch.cat((CDR3B, Epi), -1)\n",
    "    def __getitem__(self, index):\n",
    "        return self.pair[index], self.Affinity[index]\n",
    "    def __len__(self):\n",
    "        return torch.LongTensor(self.Affinity).size()[0]\n",
    "def Atchley(TCR, Epitope, Label, Length):\n",
    "    aa_vec = pk.load(open('atchley.pk', 'rb'))\n",
    "    Label = torch.LongTensor(Label).view(-1, 1)\n",
    "    n = Label.size()[0]\n",
    "    ext = list('********************') \n",
    "    tcr_embedding = torch.zeros(n, Length, 6)\n",
    "    epi_embedding = torch.zeros(n, Length, 6)\n",
    "    for ti, tcr in enumerate(TCR):\n",
    "        tcr = tcr + ' ' * (Length - len(tcr))\n",
    "        for i in range(Length):\n",
    "            tcr_embedding[ti, i, :] = torch.from_numpy(aa_vec[tcr[i]])\n",
    "\n",
    "    for ei, epi in enumerate(Epitope):\n",
    "        epi = epi + ' ' * (Length - len(epi))\n",
    "        for i in range(Length):\n",
    "            epi_embedding[ei, i, :] = torch.from_numpy(aa_vec[epi[i]])\n",
    "    return tcr_embedding[:, :, 0:5], epi_embedding[:, :, 0:5], Label \n",
    "\n",
    "def Convert_letters(seq):\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    atchley = pk.load(open('atchley.pk', 'rb'))\n",
    "    for key in atchley.keys():\n",
    "        atchley[key] = atchley[key][..., :-1]\n",
    "    for row in seq:\n",
    "        res_row = []\n",
    "        for element in row:\n",
    "            closest_key = None\n",
    "            min_distance = float('inf')\n",
    "            for key, value in atchley.items():\n",
    "                distance = np.linalg.norm(element - value)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_key = key\n",
    "            res_row.append([closest_key])\n",
    "        result.append(res_row)\n",
    "    result = np.array(result, dtype=object)\n",
    "    shape = result.shape\n",
    "    result = result.reshape((shape[0], shape[1]*shape[2]))\n",
    "    letter = []\n",
    "    for row in result:\n",
    "        row_without_symbols = [element for element in row if element.isalpha()]\n",
    "        letter.append(''.join(row_without_symbols))\n",
    "    return letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c87969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(trainfile_path,save_model_path): \n",
    "    import pandas as pd\n",
    "    import numpy as np \n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    e_type = 'Atchley'\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model,dropout=0.1, device=device)\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9)\n",
    "    n_epoch = 2\n",
    "    train = MyDataset(trainfile_path, emb_type=e_type)\n",
    "    #test = MyDataset(testfile_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    train_dataset = DataLoader(dataset=train, batch_size=b_size, shuffle=True, drop_last=True) \n",
    "    #test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model.train()\n",
    "    best_loss = 1\n",
    "    L = torch.zeros(n_epoch, 500)\n",
    "    predictions = []  \n",
    "    true_labels = [] \n",
    "    predicted_classes = []  \n",
    "    for epoch in range(n_epoch):\n",
    "        print('epoch:', epoch + 1)\n",
    "        for i, data in enumerate(train_dataset, 0):\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            label = label.unsqueeze(-1).to(device)\n",
    "            n = tcr.size()[0]\n",
    "            output = torch.unsqueeze(model(tcr, epi), 1)\n",
    "            pred = output.argmax(dim=2)\n",
    "            output = output.view(-1, 2)\n",
    "            pred = pred.view(-1)\n",
    "            label = label.long().view(-1)\n",
    "            loss = criterion(output, label) \n",
    "            correct = torch.eq(pred, label.long()).sum().float().item()\n",
    "            acc = correct / n\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                param = model.state_dict()\n",
    "            if loss == best_loss:\n",
    "                param = model.state_dict()\n",
    "            opt.zero_grad()\n",
    "            loss.backward() \n",
    "            opt.step()\n",
    "    torch.save(model.state_dict(),save_model_path+'model.pth') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d38667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_NUMBER = [1]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(s) for s in GPU_NUMBER])\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ffafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 1\n",
      "epoch: 2\n"
     ]
    }
   ],
   "source": [
    "trainfile_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/TPBTE/VDJdb/all_vdj.csv\"\n",
    "save_model_path=\"./model/Original/VDJdb_\"\n",
    "train_main(trainfile_path,save_model_path) \n",
    "\n",
    "trainfile_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/TPBTE/McPAS/all_McPAS.csv\"\n",
    "save_model_path=\"./model/Original/McPAS_\"\n",
    "train_main(trainfile_path,save_model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4c14c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tpbte import Model\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, emb_type):\n",
    "\n",
    "        self.data = pd.read_csv(path,low_memory=False)\n",
    "        self.CDR3B = self.data['CDR3B']\n",
    "        self.Epitope = self.data['Epitope']\n",
    "        self.Affinity = self.data['Affinity']\n",
    "        self.emb_type = emb_type\n",
    "        if self.emb_type == 'onehot':\n",
    "            CDR3B, Epi, self.Affinity = onehot(self.CDR3B, self.Epitope, self.Affinity)\n",
    "        elif self.emb_type == 'BLOSUM62':\n",
    "            CDR3B, Epi, self.Affinity = BLOSUM_62(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        else:\n",
    "            CDR3B, Epi, self.Affinity = Atchley(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        self.pair = torch.cat((CDR3B, Epi), -1)\n",
    "    def __getitem__(self, index):\n",
    "        return self.pair[index], self.Affinity[index]\n",
    "    def __len__(self):\n",
    "        return torch.LongTensor(self.Affinity).size()[0]\n",
    "\n",
    "def Atchley(TCR, Epitope, Label, Length):\n",
    "    aa_vec = pk.load(open('atchley.pk', 'rb'))\n",
    "    Label = torch.LongTensor(Label).view(-1, 1)\n",
    "    n = Label.size()[0]\n",
    "    ext = list('********************') \n",
    "    tcr_embedding = torch.zeros(n, Length, 6)\n",
    "    epi_embedding = torch.zeros(n, Length, 6)\n",
    "    for ti, tcr in enumerate(TCR):\n",
    "        tcr = tcr + ' ' * (Length - len(tcr))\n",
    "        for i in range(Length):\n",
    "            tcr_embedding[ti, i, :] = torch.from_numpy(aa_vec[tcr[i]])\n",
    "\n",
    "    for ei, epi in enumerate(Epitope):\n",
    "        epi = epi + ' ' * (Length - len(epi))\n",
    "        for i in range(Length):\n",
    "            epi_embedding[ei, i, :] = torch.from_numpy(aa_vec[epi[i]])\n",
    "    return tcr_embedding[:, :, 0:5], epi_embedding[:, :, 0:5], Label \n",
    "\n",
    "def Convert_letters(seq):\n",
    "    result = []\n",
    "    atchley = pk.load(open('atchley.pk', 'rb'))\n",
    "    for key in atchley.keys():\n",
    "        atchley[key] = atchley[key][..., :-1]\n",
    "    for row in seq:\n",
    "        res_row = []\n",
    "        for element in row:\n",
    "            closest_key = None\n",
    "            min_distance = float('inf')\n",
    "            for key, value in atchley.items():\n",
    "                distance = np.linalg.norm(element - value)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_key = key\n",
    "            res_row.append([closest_key])\n",
    "        result.append(res_row)\n",
    "    result = np.array(result, dtype=object)\n",
    "    shape = result.shape\n",
    "    result = result.reshape((shape[0], shape[1]*shape[2]))\n",
    "    letter = []\n",
    "    for row in result:\n",
    "        row_without_symbols = [element for element in row if element.isalpha()]\n",
    "        letter.append(''.join(row_without_symbols))\n",
    "    return letter\n",
    "\n",
    "def data_renew(pairs, emb_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if emb_type == 'onehot':\n",
    "        tcr = pairs[:, :, 0:21].type(torch.LongTensor).to(device)\n",
    "        epi = pairs[:, :, 21:-1].type(torch.LongTensor).to(device)\n",
    "    elif emb_type == 'BLOSUM62':\n",
    "        tcr = pairs[:, :, 0:20].to(device)\n",
    "        epi = pairs[:, :, 20:].to(device)\n",
    "    else:\n",
    "        tcr = pairs[:, :, 0:5].to(device)\n",
    "        epi = pairs[:, :, 5:].to(device)\n",
    "    return tcr, epi\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def validation_main(testfile_path,modelfile_path,result_path):\n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    e_type = 'Atchley'\n",
    "    test_path=testfile_path\n",
    "    test = MyDataset(test_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model, dropout=0.1, device=device)\n",
    "    model.load_state_dict(torch.load(modelfile_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    df_data = []\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    predicted_classes=[]\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataset:\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            tcr = tcr.to(device)\n",
    "            epi = epi.to(device)\n",
    "            output = model(tcr, epi)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(output[:, 1].tolist())  \n",
    "            true_labels.extend(label.tolist())\n",
    "            predicted_classes.extend(pred.tolist())\n",
    "            tcr=Convert_letters(tcr.cpu().numpy())\n",
    "            epi=Convert_letters(epi.cpu().numpy())\n",
    "            prediction_scores = output[:, 1].cpu().numpy()\n",
    "            true_labels_batch = label.cpu().numpy()\n",
    "            predicted_classes_batch = pred.cpu().numpy()\n",
    "            for i in range(len(pairs)):\n",
    "                 df_data.append({'Epitope': epi[i],'CDR3B': tcr[i],'y_true': true_labels_batch[i],\n",
    "                                 'y_prob': prediction_scores[i], \n",
    "                                 'y_pred': predicted_classes_batch[i]})\n",
    "    df_data=pd.DataFrame(df_data)           \n",
    "    df_data['y_true'] = df_data['y_true'].str[0]\n",
    "    df_data.to_csv(result_path+'probability.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        modelfile_path =\"./model/Original/VDJdb_model.pth\"\n",
    "        testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/seen/three/neg_pos/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"./result/Original/seen/three/VDJdb_\"+i+'_'+j\n",
    "        train_main(testfile_path,modelfile_path,result_path)         \n",
    "        \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        modelfile_path =\"./model/Original/VDJdb_model.pth\"\n",
    "        testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/seen/seven/neg_pos/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"./evaluate/repeat10/Prediction/all/seen/seven/VDJdb_\"+i+'_'+j\n",
    "        train_main(testfile_path,modelfile_path,result_path)    \n",
    "        \n",
    "        \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        modelfile_path =\"./model/Original/McPAS_model.pth\"\n",
    "        testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/seen/three/neg_pos/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"./evaluate/repeat10/Prediction/all/seen/three/McPAS_\"+i+'_'+j\n",
    "        train_main(testfile_path,modelfile_path,result_path) \n",
    "            \n",
    "\n",
    "        \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        modelfile_path =\"./model/Original/McPAS_model.pth\"\n",
    "        testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/seen/seven/neg_pos/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"./evaluate/repeat10/Prediction/all/seen/seven/McPAS_\"+i+'_'+j\n",
    "        train_main(testfile_path,modelfile_path,result_path) \n",
    "                        \n",
    "       \n",
    "    \n",
    "    \n",
    "            \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        modelfile_path =\"./model/Original/McPAS_model.pth\"\n",
    "        testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/unseen/CF/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"./evaluate/repeat10/Prediction/all/unseen/McPAS_\"+i+'_'+j\n",
    "        train_main(testfile_path,modelfile_path,result_path) \n",
    "                               \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        modelfile_path =\"./model/Original/VDJdb_model.pth\"\n",
    "        testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/unseen/CF/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"./evaluate/repeat10/Prediction/all/unseen/VDJdb_\"+i+'_'+j\n",
    "        train_main(testfile_path,modelfile_path,result_path) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49a7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ad689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69c55710",
   "metadata": {},
   "source": [
    "# Model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a50c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tpbte import Model\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "def data_renew(pairs, emb_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if emb_type == 'onehot':\n",
    "        tcr = pairs[:, :, 0:21].type(torch.LongTensor).to(device)\n",
    "        epi = pairs[:, :, 21:-1].type(torch.LongTensor).to(device)\n",
    "    elif emb_type == 'BLOSUM62':\n",
    "        tcr = pairs[:, :, 0:20].to(device)\n",
    "        epi = pairs[:, :, 20:].to(device)\n",
    "    else:\n",
    "        tcr = pairs[:, :, 0:5].to(device)\n",
    "        epi = pairs[:, :, 5:].to(device)\n",
    "    return tcr, epi\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, emb_type):\n",
    "\n",
    "        self.data = pd.read_csv(path,low_memory=False)\n",
    "        self.CDR3B = self.data['CDR3B']\n",
    "        self.Epitope = self.data['Epitope']\n",
    "        self.Affinity = self.data['Affinity']\n",
    "        self.emb_type = emb_type\n",
    "        if self.emb_type == 'onehot':\n",
    "            CDR3B, Epi, self.Affinity = onehot(self.CDR3B, self.Epitope, self.Affinity)\n",
    "        elif self.emb_type == 'BLOSUM62':\n",
    "            CDR3B, Epi, self.Affinity = BLOSUM_62(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        else:\n",
    "            CDR3B, Epi, self.Affinity = Atchley(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        self.pair = torch.cat((CDR3B, Epi), -1)\n",
    "    def __getitem__(self, index):\n",
    "        return self.pair[index], self.Affinity[index]\n",
    "    def __len__(self):\n",
    "        return torch.LongTensor(self.Affinity).size()[0]\n",
    "def Atchley(TCR, Epitope, Label, Length):\n",
    "    aa_vec = pk.load(open('atchley.pk', 'rb'))\n",
    "    Label = torch.LongTensor(Label).view(-1, 1)\n",
    "    n = Label.size()[0]\n",
    "    ext = list('********************') \n",
    "    tcr_embedding = torch.zeros(n, Length, 6)\n",
    "    epi_embedding = torch.zeros(n, Length, 6)\n",
    "    for ti, tcr in enumerate(TCR):\n",
    "        tcr = tcr + ' ' * (Length - len(tcr))\n",
    "        for i in range(Length):\n",
    "            tcr_embedding[ti, i, :] = torch.from_numpy(aa_vec[tcr[i]])\n",
    "\n",
    "    for ei, epi in enumerate(Epitope):\n",
    "        epi = epi + ' ' * (Length - len(epi))\n",
    "        for i in range(Length):\n",
    "            epi_embedding[ei, i, :] = torch.from_numpy(aa_vec[epi[i]])\n",
    "    return tcr_embedding[:, :, 0:5], epi_embedding[:, :, 0:5], Label \n",
    "\n",
    "def Convert_letters(seq):\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    atchley = pk.load(open('atchley.pk', 'rb'))\n",
    "    for key in atchley.keys():\n",
    "        atchley[key] = atchley[key][..., :-1]\n",
    "    for row in seq:\n",
    "        res_row = []\n",
    "        for element in row:\n",
    "            closest_key = None\n",
    "            min_distance = float('inf')\n",
    "            for key, value in atchley.items():\n",
    "                distance = np.linalg.norm(element - value)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_key = key\n",
    "            res_row.append([closest_key])\n",
    "        result.append(res_row)\n",
    "    result = np.array(result, dtype=object)\n",
    "    shape = result.shape\n",
    "    result = result.reshape((shape[0], shape[1]*shape[2]))\n",
    "    letter = []\n",
    "    for row in result:\n",
    "        row_without_symbols = [element for element in row if element.isalpha()]\n",
    "        letter.append(''.join(row_without_symbols))\n",
    "    return letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45ef345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(trainfile_path,testfile_path,save_model_path,result_path): \n",
    "    import pandas as pd\n",
    "    import numpy as np \n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    e_type = 'Atchley'\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model,dropout=0.1, device=device)\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9)\n",
    "    n_epoch = 2\n",
    "    train = MyDataset(trainfile_path, emb_type=e_type)\n",
    "    test = MyDataset(testfile_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    train_dataset = DataLoader(dataset=train, batch_size=b_size, shuffle=True, drop_last=True) \n",
    "    test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model.train()\n",
    "    best_loss = 1\n",
    "    L = torch.zeros(n_epoch, 500)\n",
    "    predictions = []  # Initialize predictions list\n",
    "    true_labels = []  # Initialize true_labels list\n",
    "    predicted_classes = []  # Initialize predicted_classes list\n",
    "    for epoch in range(n_epoch):\n",
    "        print('epoch:', epoch + 1)\n",
    "        for i, data in enumerate(train_dataset, 0):\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            label = label.unsqueeze(-1).to(device)\n",
    "            n = tcr.size()[0]\n",
    "            output = torch.unsqueeze(model(tcr, epi), 1)\n",
    "            pred = output.argmax(dim=2)\n",
    "            output = output.view(-1, 2)\n",
    "            pred = pred.view(-1)\n",
    "            label = label.long().view(-1)\n",
    "            loss = criterion(output, label) \n",
    "            correct = torch.eq(pred, label.long()).sum().float().item()\n",
    "            acc = correct / n\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                param = model.state_dict()\n",
    "            if loss == best_loss:\n",
    "                param = model.state_dict()\n",
    "            opt.zero_grad()\n",
    "            loss.backward() \n",
    "            opt.step()\n",
    "    torch.save(model.state_dict(),save_model_path+'model.pth')  \n",
    "    print('End training. Begin testing')\n",
    "    good_model = model\n",
    "    good_model.load_state_dict(param)\n",
    "    good_model.eval()\n",
    "    good_model.to(device)\n",
    "    df_data = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataset, 0):\n",
    "            correct = 0  \n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            output = good_model(tcr, epi)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(output[:, 1].tolist())  \n",
    "            true_labels.extend(label.tolist())\n",
    "            predicted_classes.extend(pred.tolist())\n",
    "\n",
    "            tcr=Convert_letters(tcr.cpu().numpy())\n",
    "            epi=Convert_letters(epi.cpu().numpy())\n",
    "            prediction_scores = output[:, 1].cpu().numpy()\n",
    "            true_labels_batch = label.cpu().numpy()\n",
    "            predicted_classes_batch = pred.cpu().numpy()\n",
    "            for i in range(len(pairs)):\n",
    "                 df_data.append({'Epitope': epi[i],'CDR3B': tcr[i],'y_true': true_labels_batch[i],\n",
    "                                 'y_prob': prediction_scores[i], \n",
    "                                 'y_pred': predicted_classes_batch[i]})\n",
    "            torch.cuda.empty_cache()\n",
    "    df_data=pd.DataFrame(df_data)           \n",
    "    df_data['y_true'] = df_data['y_true'].str[0]\n",
    "    df_data.to_csv(result_path+'probability.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c038fa3",
   "metadata": {},
   "source": [
    "# pair50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=['healthy','patient']\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            trainfile_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/\"+i+\"/\"+k+'_'+j+\"train.csv\"\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/\"+i+\"/\"+k+'_'+\"1_1test.csv\"\n",
    "            save_model_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/TPBTE/model/Retrain/pair50/\"+i+\"/\"+k+'_'+j\n",
    "            result_path=\"./result/pair50/seen/test/\"+i+\"/\"+k+'_'+j\n",
    "            train_main(trainfile_path,testfile_path,save_model_path,result_path) \n",
    "\n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            trainfile_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/\"+i+\"/\"+k+'_'+j+\"train.csv\"\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/\"+i+\"/\"+k+'_'+\"1_1test.csv\"\n",
    "            save_model_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/TPBTE/model/Retrain/pair50/\"+i+\"/\"+k+'_'+j\n",
    "            result_path=\"./result/pair50/seen/test/\"+i+\"/\"+k+'_'+j\n",
    "            train_main(trainfile_path,testfile_path,save_model_path,result_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce8f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1297a49",
   "metadata": {},
   "source": [
    "# pair300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c975f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "End training. Begin testing\n",
      "cuda:0\n",
      "epoch: 1\n"
     ]
    }
   ],
   "source": [
    "pair=['more300','300','200','100','10']\n",
    "database=['healthy','patient']\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            for l in pair:\n",
    "                trainfile_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/\"+l+\"/\"+i+\"/\"+k+'_'+j+\"train.csv\"\n",
    "                testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/more300/\"+i+\"/\"+k+'_'+j+\"test.csv\"\n",
    "                save_model_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/TPBTE/model/Retrain/pair300/seen/\"+l+\"/\"+i+\"/\"+k+'_'+j\n",
    "                result_path=\"./result/pair300/seen/\"+l+\"/\"+i+\"/\"+k+'_'+j\n",
    "                train_main(trainfile_path,testfile_path,save_model_path,result_path) \n",
    "\n",
    "                \n",
    "\n",
    "pair=['more300','300','200','100','10']\n",
    "database=['Antigen_specificity']\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            for l in pair:\n",
    "                trainfile_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/\"+l+\"/\"+i+\"/\"+k+'_'+j+\"train.csv\"\n",
    "                testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/more300/\"+i+\"/\"+k+'_'+j+\"test.csv\"\n",
    "                save_model_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/TPBTE/model/Retrain/pair300/seen/\"+l+\"/\"+i+\"/\"+k+'_'+j\n",
    "                result_path=\"./result/pair300/seen/\"+l+\"/\"+i+\"/\"+k+'_'+j\n",
    "                train_main(trainfile_path,testfile_path,save_model_path,result_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d79bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5afb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e2b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_main(testfile_path,modelfile_path,result_path):\n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    e_type = 'Atchley'\n",
    "    test_path=testfile_path\n",
    "    test = MyDataset(test_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model, dropout=0.1, device=device)\n",
    "    model.load_state_dict(torch.load(modelfile_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    df_data = []\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    predicted_classes=[]\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataset:\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            tcr = tcr.to(device)\n",
    "            epi = epi.to(device)\n",
    "            output = model(tcr, epi)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(output[:, 1].tolist())  \n",
    "            true_labels.extend(label.tolist())\n",
    "            predicted_classes.extend(pred.tolist())\n",
    "            tcr=Convert_letters(tcr.cpu().numpy())\n",
    "            epi=Convert_letters(epi.cpu().numpy())\n",
    "            prediction_scores = output[:, 1].cpu().numpy()\n",
    "            true_labels_batch = label.cpu().numpy()\n",
    "            predicted_classes_batch = pred.cpu().numpy()\n",
    "            for i in range(len(pairs)):\n",
    "                 df_data.append({'Epitope': epi[i],'CDR3B': tcr[i],'y_true': true_labels_batch[i],\n",
    "                                 'y_prob': prediction_scores[i], \n",
    "                                 'y_pred': predicted_classes_batch[i]})\n",
    "    df_data=pd.DataFrame(df_data)           \n",
    "    df_data['y_true'] = df_data['y_true'].str[0]\n",
    "    df_data.to_csv(result_path+'probability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa015ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d277b08",
   "metadata": {},
   "source": [
    "# validaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c5279",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy','patient']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+i+\"/\"+k+'_'+\"1_1Validation.csv\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+i+\"/\"+k+'_'+j+\"model.pth\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+i+\"/\"+k+'_'+j\n",
    "            validation_main(testfile_path,modelfile_path,result_path)\n",
    "\n",
    "import pandas as pd\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4']\n",
    "database=['Antigen_specificity']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+i+\"/\"+k+'_'+\"1_1Validation.csv\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+i+\"/\"+k+'_'+j+\"model.pth\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+i+\"/\"+k+'_'+j\n",
    "            validation_main(testfile_path,modelfile_path,result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079a111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b6af6e",
   "metadata": {},
   "source": [
    "# unkonwn-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy','patient']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+i+\"/\"+k+'_'+\"1_1test.csv\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+i+\"/\"+k+'_'+j+\"model.pth\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+i+\"/\"+k+'_'+j\n",
    "            validation_main(testfile_path,modelfile_path,result_path)\n",
    "\n",
    "import pandas as pd\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4']\n",
    "database=['Antigen_specificity']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+i+\"/\"+k+'_'+\"1_1test.csv\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+i+\"/\"+k+'_'+j+\"model.pth\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+i+\"/\"+k+'_'+j\n",
    "            validation_main(testfile_path,modelfile_path,result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235d85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeb39f8b",
   "metadata": {},
   "source": [
    "# unkonwn-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a7a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy','patient']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+i+\"/\"+k+'_'+\"1_1validation.csv\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+i+\"/\"+k+'_'+j+\"model.pth\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+i+\"/\"+k+'_'+j\n",
    "            validation_main(testfile_path,modelfile_path,result_path)\n",
    "\n",
    "import pandas as pd\n",
    "name1=['1','2','3','4','5']\n",
    "name=['1_1','1_2','1_4']\n",
    "database=['Antigen_specificity']\n",
    "for i in database:\n",
    "    for j in name:\n",
    "        for k in name1:\n",
    "            testfile_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+i+\"/\"+k+'_'+\"1_1validation.csv\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+i+\"/\"+k+'_'+j+\"model.pth\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+i+\"/\"+k+'_'+j\n",
    "            validation_main(testfile_path,modelfile_path,result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf22a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb832ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d451434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676e9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031bc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc720ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17041d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd13d5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea21c289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a0ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f75ee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7beec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b9abd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38bc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d94da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
