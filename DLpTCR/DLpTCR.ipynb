{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d59141",
   "metadata": {},
   "source": [
    "# Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9ef81726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "try:\n",
    "    import tensorflow.python.keras as keras\n",
    "except:\n",
    "    import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,matthews_corrcoef,classification_report,confusion_matrix,precision_score,recall_score\n",
    "from sklearn.metrics import f1_score,roc_auc_score, auc\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "90706c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/code/\")\n",
    "from aaindexValues import aaindex1PCAValues\n",
    "def pca_Validation(testFile ):\n",
    "    \n",
    "    def pca_code(seqs:list, row=30, n_features=16):\n",
    "        aadict = aaindex1PCAValues(n_features)\n",
    "        x = []\n",
    "        col = n_features + 1\n",
    "        for i in range(len(seqs)):\n",
    "            seq = seqs[i]\n",
    "            n = len(seq)\n",
    "            t = np.zeros(shape=(row, col))\n",
    "            j = 0\n",
    "            while j < n and j < row:\n",
    "                t[j, :-1] = aadict[seq[j]]\n",
    "                t[j, -1] = 0\n",
    "                j += 1\n",
    "            while j < row:\n",
    "                t[j, -1] = 1\n",
    "                j = j + 1\n",
    "            x.append(t)\n",
    "        return np.array(x)\n",
    "\n",
    "    def read_seqs(file, model=1):\n",
    "        data = pd.read_csv(file)\n",
    "        labels = data.Affinity\n",
    "        cdr3 = data.CDR3B\n",
    "        epitope = data.Epitope\n",
    "        cdr3_seqs, epit_seqs = [], []\n",
    "        for i in range(len(epitope)):\n",
    "            if model == 1:\n",
    "                cdr3_seqs.append(cdr3[i][2:-1])\n",
    "            elif model == 2:\n",
    "                cdr3_seqs.append(cdr3[i])\n",
    "            epit_seqs.append(epitope[i])\n",
    "\n",
    "        return cdr3_seqs, epit_seqs, labels\n",
    "\n",
    "    def load_data(col=20, row=9, m=1):\n",
    "        test_cdr3_seqs, test_epit_seqs, test_labels = read_seqs(testFile, m)\n",
    "        x_test = np.ndarray(shape=(len(test_cdr3_seqs), row, col + 1, 2))\n",
    "        x_test[:, :, :, 0] = pca_code(test_cdr3_seqs, row, col)\n",
    "        x_test[:, :, :, 1] = pca_code(test_epit_seqs, row, col)\n",
    "\n",
    "        y_test = np.array(test_labels)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "        return (x_test, y_test)\n",
    "    \n",
    "    m = 2\n",
    "    row = 20\n",
    "    TCRB_RESNET_Feature, _ = load_data(col=10, row=row, m=m)\n",
    "    TCRB_FULL_Feature, _ = load_data(col=18, row=row, m=m)\n",
    "    TCRB_CNN_Feature, _ = load_data(col=20, row=row, m=m)\n",
    "    return TCRB_FULL_Feature, TCRB_CNN_Feature, TCRB_RESNET_Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12151348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prediction(data_path,result_path): \n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()   \n",
    "    \n",
    "    data = pd.read_csv(data_path)\n",
    "    FULL_Feature, CNN_Feature, RESNET_Feature= pca_Validation(data_path)\n",
    "\n",
    "    FULL_model = load_model('./model/FULL_B_ALL_pca18.h5')\n",
    "    CNN_model = load_model('./model/CNN_B_ALL_pca20.h5')\n",
    "    RESNET_model = load_model('./model/RESNET_B_ALL_pca10.h5') \n",
    "    \n",
    "    FULL_X = FULL_Feature\n",
    "    FULL_X = FULL_X.reshape([len(FULL_X),20,19,2])\n",
    "\n",
    "    CNN_X = CNN_Feature\n",
    "    CNN_X = CNN_X.reshape([len(CNN_X),20,21,2])  \n",
    "    \n",
    "    RESNET_X = RESNET_Feature\n",
    "    RESNET_X = RESNET_X.reshape([len(RESNET_X),20,11,2])\n",
    "\n",
    "    Y_PRED_FULL = FULL_model.predict(FULL_X)\n",
    "    Y_PRED_CNN = CNN_model.predict(CNN_X)\n",
    "    Y_PRED_RESNET = RESNET_model.predict(RESNET_X)\n",
    "    \n",
    "    Y_pred_FULL= Y_PRED_FULL[:, 1]\n",
    "    Y_pred_CNN= Y_PRED_CNN[:, 1]\n",
    "    Y_pred_RESNET= Y_PRED_RESNET[:, 1]\n",
    "    \n",
    "    del FULL_model\n",
    "    del CNN_model\n",
    "    del RESNET_model\n",
    "\n",
    "    df_full = pd.DataFrame({'CDR3B': data.CDR3B, 'Epitope': data.Epitope, 'y_true': data.Affinity, 'y_prob': Y_pred_FULL})\n",
    "    df_full['y_pred'] = df_full['y_prob'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    df_full.to_csv(result_path + 'FULL_probability.csv', index=False)\n",
    "    df_cnn = pd.DataFrame({'CDR3B': data.CDR3B, 'Epitope': data.Epitope, 'y_true': data.Affinity, 'y_prob': Y_pred_CNN})\n",
    "    df_cnn['y_pred'] = df_cnn['y_prob'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    df_cnn.to_csv(result_path + 'CNN_probability.csv', index=False)\n",
    "    df_resnet = pd.DataFrame({'CDR3B': data.CDR3B, 'Epitope': data.Epitope, 'y_true': data.Affinity, 'y_prob': Y_pred_RESNET})\n",
    "    df_resnet['y_pred'] = df_resnet['y_prob'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    df_resnet.to_csv(result_path + 'RESNET_probability.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        data_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/seen/seven/neg_pos/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/result/Original/seen/seven/\"+i+'_'+j+'_'\n",
    "        prediction(data_path,result_path)\n",
    "        \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        data_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/seen/three/neg_pos/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/result/Original/seen/three/\"+i+'_'+j+'_'\n",
    "        prediction(data_path,result_path)\n",
    "        \n",
    "name=['1','2','3']\n",
    "me=['health','Diseases','antigen_specificity']\n",
    "for i in name:\n",
    "    for j in me:\n",
    "        data_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Prediction/all/unseen/CF/\"+i+'_'+j+'.csv'\n",
    "        result_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/result/Original/unseen/\"+i+'_'+j+'_'\n",
    "        prediction(data_path,result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eddce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec88cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88e712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ad40a62",
   "metadata": {},
   "source": [
    "# Model Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adb8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix\n",
    "from sklearn.metrics import f1_score,roc_auc_score,recall_score,precision_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "from aaindexValues import aaindex1PCAValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea58f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d727e4",
   "metadata": {},
   "source": [
    "# time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426a6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_Validation( data_path,save_path):\n",
    "    def pca_code(seqs: list, row=30, n_features=16):\n",
    "        aadict = aaindex1PCAValues(n_features)\n",
    "        x = []\n",
    "        col = n_features + 1\n",
    "        for seq in seqs:\n",
    "            t = np.zeros(shape=(row, col))\n",
    "            for j in range(min(len(seq), row)):\n",
    "                t[j, :-1] = aadict[seq[j]]\n",
    "            t[len(seq):, -1] = 1  # Pad remaining rows\n",
    "            x.append(t)\n",
    "        return np.array(x)\n",
    "\n",
    "    def read_seqs(file, model=1):\n",
    "        data = pandas.read_csv(file)\n",
    "        labels = data.Affinity\n",
    "        cdr3 = data.CDR3B\n",
    "        epitope = data.Epitope\n",
    "\n",
    "        cdr3_seqs = [cdr3[i][2:-1] if model == 1 else cdr3[i] for i in range(len(epitope))]\n",
    "        epit_seqs = [epitope[i] for i in range(len(epitope))]\n",
    "\n",
    "        return cdr3_seqs, epit_seqs, labels\n",
    "\n",
    "    def load_data(test_file, col=20, row=9, m=1):\n",
    "        test_cdr3_seqs, test_epit_seqs, test_labels = read_seqs(test_file, m)\n",
    "        x_test = np.ndarray(shape=(len(test_cdr3_seqs), row, col + 1, 2))\n",
    "        x_test[:, :, :, 0] = pca_code(test_cdr3_seqs, row, col)\n",
    "        x_test[:, :, :, 1] = pca_code(test_epit_seqs, row, col)\n",
    "\n",
    "        y_test = np.array(test_labels)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "        return x_test, y_test\n",
    "\n",
    "    test_file = data_path +\".csv\"\n",
    "    \n",
    "    for col in [10, 18, 20]:\n",
    "        x_test, y_test = load_data(test_file, col=col, row=20, m=2)\n",
    "        np.save(f\"{save_path}_TCRB_PCA{col}_feature_array\", x_test)\n",
    "        np.save(f\"{save_path}_TCRB_PCA{col}_label_array\", y_test)\n",
    "        \n",
    "dsize=['1000','5000','10000','100000','1000000']\n",
    "for i in size:\n",
    "    data_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/time/data_\"+i\n",
    "    save_path=\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/top5/\"+i\n",
    "    pca_Validation(data_path, save_path)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74eb3ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9f5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pca_Validation(validation_path, ratio_name, name1, save_path, prefix='train'):\n",
    "    def pca_code(seqs: list, row=30, n_features=16):\n",
    "        aadict = aaindex1PCAValues(n_features)\n",
    "        x = []\n",
    "        col = n_features + 1\n",
    "        for seq in seqs:\n",
    "            t = np.zeros(shape=(row, col))\n",
    "            for j in range(min(len(seq), row)):\n",
    "                t[j, :-1] = aadict[seq[j]]\n",
    "            t[len(seq):, -1] = 1  # Pad remaining rows\n",
    "            x.append(t)\n",
    "        return np.array(x)\n",
    "\n",
    "    def read_seqs(file, model=1):\n",
    "        data = pandas.read_csv(file)\n",
    "        labels = data.Affinity\n",
    "        cdr3 = data.CDR3B\n",
    "        epitope = data.Epitope\n",
    "\n",
    "        cdr3_seqs = [cdr3[i][2:-1] if model == 1 else cdr3[i] for i in range(len(epitope))]\n",
    "        epit_seqs = [epitope[i] for i in range(len(epitope))]\n",
    "\n",
    "        return cdr3_seqs, epit_seqs, labels\n",
    "\n",
    "    def load_data(test_file, col=20, row=9, m=1):\n",
    "        test_cdr3_seqs, test_epit_seqs, test_labels = read_seqs(test_file, m)\n",
    "        x_test = np.ndarray(shape=(len(test_cdr3_seqs), row, col + 1, 2))\n",
    "        x_test[:, :, :, 0] = pca_code(test_cdr3_seqs, row, col)\n",
    "        x_test[:, :, :, 1] = pca_code(test_epit_seqs, row, col)\n",
    "\n",
    "        y_test = np.array(test_labels)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "        return x_test, y_test\n",
    "\n",
    "    test_file = f\"{validation_path}/{name1}_{ratio_name}train.csv\"\n",
    "    \n",
    "    for col in [10, 18, 20]:\n",
    "        x_test, y_test = load_data(test_file, col=col, row=20, m=2)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_feature_array\", x_test)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_label_array\", y_test)\n",
    "\n",
    "\n",
    "def execute_validation(database_list, ratio_name_list, name1_list, base_data_path, base_save_path, prefix='train'):\n",
    "    for db in database_list:\n",
    "        for ratio in ratio_name_list:\n",
    "            for name in name1_list:\n",
    "                data_path = f\"{base_data_path}/{db}\"\n",
    "                save_path = f\"{base_save_path}/{db}\"\n",
    "                pca_Validation(data_path, ratio, name, save_path, prefix=prefix)\n",
    "                \n",
    "data_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50\"\n",
    "save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair50/seen/test\"\n",
    "execute_validation(\n",
    "    database_list=['healthy', 'patient'],\n",
    "    ratio_name_list=['1_1', '1_2', '1_4', '1_6', '1_8'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_data_path=data_path, \n",
    "    base_save_path=save_path)\n",
    "\n",
    "execute_validation(\n",
    "    database_list=['Antigen_specificity'],\n",
    "    ratio_name_list=['1_1', '1_2', '1_4'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_data_path=data_path, \n",
    "    base_save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "897ea5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luyanping/miniconda3/envs/DLpTCR/lib/python3.7/site-packages/ipykernel_launcher.py:26: DtypeWarning: Columns (5,6,7,8,10) have mixed types.Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "def execute_validation_v2(database_list, ratio_name_list, pair_list, name1_list, base_train_path, base_save_path, prefix='train'):\n",
    "    for db in database_list:\n",
    "        for ratio in ratio_name_list:\n",
    "            for pair in pair_list:\n",
    "                for name in name1_list:\n",
    "                    train_path = f\"{base_train_path}/{pair}/{db}\"\n",
    "                    save_path = f\"{base_save_path}/{pair}/{db}\"\n",
    "                    pca_Validation(train_path, ratio, name, save_path, prefix=prefix)\n",
    "\n",
    "base_train_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300\"\n",
    "base_save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair300\"\n",
    "execute_validation_v2(\n",
    "    database_list=['healthy', 'patient', 'Antigen_specificity'],\n",
    "    ratio_name_list=['1_1'],\n",
    "    pair_list=['more300','300', '200', '100', '10'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_train_path=base_train_path,\n",
    "    base_save_path=base_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5303ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_Validation(validation_path, ratio_name, name1, save_path, prefix='test'):\n",
    "    def pca_code(seqs: list, row=30, n_features=16):\n",
    "        aadict = aaindex1PCAValues(n_features)\n",
    "        x = []\n",
    "        col = n_features + 1\n",
    "        for seq in seqs:\n",
    "            t = np.zeros(shape=(row, col))\n",
    "            for j in range(min(len(seq), row)):\n",
    "                t[j, :-1] = aadict[seq[j]]\n",
    "            t[len(seq):, -1] = 1  # Pad remaining rows\n",
    "            x.append(t)\n",
    "        return np.array(x)\n",
    "\n",
    "    def read_seqs(file, model=1):\n",
    "        data = pandas.read_csv(file)\n",
    "        labels = data.Affinity\n",
    "        cdr3 = data.CDR3B\n",
    "        epitope = data.Epitope\n",
    "\n",
    "        cdr3_seqs = [cdr3[i][2:-1] if model == 1 else cdr3[i] for i in range(len(epitope))]\n",
    "        epit_seqs = [epitope[i] for i in range(len(epitope))]\n",
    "\n",
    "        return cdr3_seqs, epit_seqs, labels\n",
    "\n",
    "    def load_data(test_file, col=20, row=9, m=1):\n",
    "        test_cdr3_seqs, test_epit_seqs, test_labels = read_seqs(test_file, m)\n",
    "        x_test = np.ndarray(shape=(len(test_cdr3_seqs), row, col + 1, 2))\n",
    "        x_test[:, :, :, 0] = pca_code(test_cdr3_seqs, row, col)\n",
    "        x_test[:, :, :, 1] = pca_code(test_epit_seqs, row, col)\n",
    "\n",
    "        y_test = np.array(test_labels)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "        return x_test, y_test\n",
    "\n",
    "    test_file = f\"{validation_path}/{name1}_{ratio_name}test.csv\"\n",
    "    \n",
    "    for col in [10, 18, 20]:\n",
    "        x_test, y_test = load_data(test_file, col=col, row=20, m=2)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_feature_array\", x_test)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_label_array\", y_test)\n",
    "\n",
    "def execute_validation(database_list, ratio_name_list, name1_list, base_data_path, base_save_path, prefix='test'):\n",
    "    for db in database_list:\n",
    "        for ratio in ratio_name_list:\n",
    "            for name in name1_list:\n",
    "                data_path = f\"{base_data_path}/{db}\"\n",
    "                save_path = f\"{base_save_path}/{db}\"\n",
    "                pca_Validation(data_path, ratio, name, save_path, prefix=prefix)\n",
    "                \n",
    "data_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50\"\n",
    "save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair50/seen/test\"\n",
    "execute_validation(\n",
    "    database_list=['healthy', 'patient', 'Antigen_specificity'],\n",
    "    ratio_name_list=['1_1'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_data_path=data_path, \n",
    "    base_save_path=save_path)\n",
    "\n",
    "                \n",
    "data_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"\n",
    "save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair50/unseen/test\"\n",
    "execute_validation(\n",
    "    database_list=['healthy', 'patient', 'Antigen_specificity'],\n",
    "    ratio_name_list=['1_1'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_data_path=data_path, \n",
    "    base_save_path=save_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8593ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_validation_v2(database_list, ratio_name_list, pair_list, name1_list, base_train_path, base_save_path, prefix='test'):\n",
    "    for db in database_list:\n",
    "        for ratio in ratio_name_list:\n",
    "            for pair in pair_list:\n",
    "                for name in name1_list:\n",
    "                    train_path = f\"{base_train_path}/{pair}/{db}\"\n",
    "                    save_path = f\"{base_save_path}/{pair}/{db}\"\n",
    "                    pca_Validation(train_path, ratio, name, save_path, prefix=prefix)\n",
    "\n",
    "base_train_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300\"\n",
    "base_save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair300\"\n",
    "execute_validation_v2(\n",
    "    database_list=['healthy', 'patient', 'Antigen_specificity'],\n",
    "    ratio_name_list=['1_1'],\n",
    "    pair_list=['more300'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_train_path=base_train_path,\n",
    "    base_save_path=base_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1b13a9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pca_Validation(validation_path, ratio_name, name1, save_path, prefix='validation'):\n",
    "    def pca_code(seqs: list, row=30, n_features=16):\n",
    "        aadict = aaindex1PCAValues(n_features)\n",
    "        x = []\n",
    "        col = n_features + 1\n",
    "        for seq in seqs:\n",
    "            t = np.zeros(shape=(row, col))\n",
    "            for j in range(min(len(seq), row)):\n",
    "                t[j, :-1] = aadict[seq[j]]\n",
    "            t[len(seq):, -1] = 1  # Pad remaining rows\n",
    "            x.append(t)\n",
    "        return np.array(x)\n",
    "\n",
    "    def read_seqs(file, model=1):\n",
    "        data = pandas.read_csv(file)\n",
    "        labels = data.Affinity\n",
    "        cdr3 = data.CDR3B\n",
    "        epitope = data.Epitope\n",
    "\n",
    "        cdr3_seqs = [cdr3[i][2:-1] if model == 1 else cdr3[i] for i in range(len(epitope))]\n",
    "        epit_seqs = [epitope[i] for i in range(len(epitope))]\n",
    "\n",
    "        return cdr3_seqs, epit_seqs, labels\n",
    "\n",
    "    def load_data(test_file, col=20, row=9, m=1):\n",
    "        test_cdr3_seqs, test_epit_seqs, test_labels = read_seqs(test_file, m)\n",
    "        x_test = np.ndarray(shape=(len(test_cdr3_seqs), row, col + 1, 2))\n",
    "        x_test[:, :, :, 0] = pca_code(test_cdr3_seqs, row, col)\n",
    "        x_test[:, :, :, 1] = pca_code(test_epit_seqs, row, col)\n",
    "\n",
    "        y_test = np.array(test_labels)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "        return x_test, y_test\n",
    "\n",
    "    test_file = f\"{validation_path}/{name1}_{ratio_name}Validation.csv\"\n",
    "    \n",
    "    for col in [10, 18, 20]:\n",
    "        x_test, y_test = load_data(test_file, col=col, row=20, m=2)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_feature_array\", x_test)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_label_array\", y_test)\n",
    "def execute_validation(database_list, ratio_name_list, name1_list, base_data_path, base_save_path, prefix='validation'):\n",
    "    for db in database_list:\n",
    "        for ratio in ratio_name_list:\n",
    "            for name in name1_list:\n",
    "                data_path = f\"{base_data_path}/{db}\"\n",
    "                save_path = f\"{base_save_path}/{db}\"\n",
    "                pca_Validation(data_path, ratio, name, save_path, prefix=prefix)\n",
    "                \n",
    "                \n",
    "                \n",
    "data_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation\"\n",
    "save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair50/seen/validation\"\n",
    "execute_validation(\n",
    "    database_list=['healthy', 'patient', 'Antigen_specificity'],\n",
    "    ratio_name_list=['1_1'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_data_path=data_path, \n",
    "    base_save_path=save_path)\n",
    "def pca_Validation(validation_path, ratio_name, name1, save_path, prefix='validation'):\n",
    "    def pca_code(seqs: list, row=30, n_features=16):\n",
    "        aadict = aaindex1PCAValues(n_features)\n",
    "        x = []\n",
    "        col = n_features + 1\n",
    "        for seq in seqs:\n",
    "            t = np.zeros(shape=(row, col))\n",
    "            for j in range(min(len(seq), row)):\n",
    "                t[j, :-1] = aadict[seq[j]]\n",
    "            t[len(seq):, -1] = 1  # Pad remaining rows\n",
    "            x.append(t)\n",
    "        return np.array(x)\n",
    "\n",
    "    def read_seqs(file, model=1):\n",
    "        data = pandas.read_csv(file)\n",
    "        labels = data.Affinity\n",
    "        cdr3 = data.CDR3B\n",
    "        epitope = data.Epitope\n",
    "\n",
    "        cdr3_seqs = [cdr3[i][2:-1] if model == 1 else cdr3[i] for i in range(len(epitope))]\n",
    "        epit_seqs = [epitope[i] for i in range(len(epitope))]\n",
    "\n",
    "        return cdr3_seqs, epit_seqs, labels\n",
    "\n",
    "    def load_data(test_file, col=20, row=9, m=1):\n",
    "        test_cdr3_seqs, test_epit_seqs, test_labels = read_seqs(test_file, m)\n",
    "        x_test = np.ndarray(shape=(len(test_cdr3_seqs), row, col + 1, 2))\n",
    "        x_test[:, :, :, 0] = pca_code(test_cdr3_seqs, row, col)\n",
    "        x_test[:, :, :, 1] = pca_code(test_epit_seqs, row, col)\n",
    "\n",
    "        y_test = np.array(test_labels)\n",
    "        y_test = to_categorical(y_test, 2)\n",
    "        return x_test, y_test\n",
    "\n",
    "    test_file = f\"{validation_path}/{name1}_{ratio_name}validation.csv\"\n",
    "    \n",
    "    for col in [10, 18, 20]:\n",
    "        x_test, y_test = load_data(test_file, col=col, row=20, m=2)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_feature_array\", x_test)\n",
    "        np.save(f\"{save_path}/{name1}_{ratio_name}{prefix}_TCRB_PCA{col}_label_array\", y_test)\n",
    "def execute_validation(database_list, ratio_name_list, name1_list, base_data_path, base_save_path, prefix='validation'):\n",
    "    for db in database_list:\n",
    "        for ratio in ratio_name_list:\n",
    "            for name in name1_list:\n",
    "                data_path = f\"{base_data_path}/{db}\"\n",
    "                save_path = f\"{base_save_path}/{db}\"\n",
    "                pca_Validation(data_path, ratio, name, save_path, prefix=prefix)\n",
    "                \n",
    "\n",
    "                \n",
    "data_path =\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"\n",
    "save_path = \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/data/pair50/unseen/validation\"\n",
    "execute_validation(\n",
    "    database_list=['healthy', 'patient', 'Antigen_specificity'],\n",
    "    ratio_name_list=['1_1'],\n",
    "    name1_list=['1', '2', '3', '4', '5'],\n",
    "    base_data_path=data_path, \n",
    "    base_save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8398c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0a4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "770b9cd6",
   "metadata": {},
   "source": [
    "# FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c9c1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FULL_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path):    \n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        import tensorflow.python.keras as keras\n",
    "    except:\n",
    "        import tensorflow.keras as keras\n",
    "\n",
    "    from tensorflow.python.keras import layers\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import accuracy_score,matthews_corrcoef,classification_report,confusion_matrix,precision_score,recall_score\n",
    "    from sklearn.metrics import f1_score,roc_auc_score, auc\n",
    "    from keras import regularizers\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    from tensorflow.python.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "    from keras.utils import plot_model\n",
    "    #from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.utils import shuffle\n",
    "    from tensorflow.python.keras.models import load_model\n",
    "    import matplotlib.pyplot as plt\n",
    "    import csv\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "    def FULL_pca18(modelfile,Dropout1=0,Epochs= 20,Batch_size=64,PCA_num = 18):\n",
    "        train_Feature = np.load(trainfile_path+\"train_TCRB_PCA{}_feature_array.npy\".format(PCA_num))    \n",
    "        train_Label = np.load(trainfile_path+\"train_TCRB_PCA{}_label_array.npy\".format(PCA_num))\n",
    "        test_Feature = np.load(testfile_path+\"test_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "        test_Label = np.load(testfile_path+\"test_TCRB_PCA{}_label_array.npy\".format(PCA_num))                 \n",
    "        X_train = train_Feature\n",
    "        Y_train = train_Label            \n",
    "        X_test = test_Feature\n",
    "        Y_test = test_Label \n",
    "        X_train,Y_train = shuffle(X_train,Y_train)\n",
    "        X_test,Y_test = shuffle(X_test,Y_test)\n",
    "        X_train= X_train.reshape([len(X_train),20,PCA_num+1,2])\n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        X_test=tf.cast(X_test, tf.float32)\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(20,PCA_num+1,2)),\n",
    "\n",
    "            tf.keras.layers.Dense(256,activation='relu'),# kernel_regularizer=regularizers.l2(0.01)),#  activation='relu',\n",
    "            tf.keras.layers.Dense(512,activation='relu'),# kernel_regularizer=regularizers.l2(0.01)),#  activation='relu',\n",
    "\n",
    "            tf.keras.layers.Dense(256,activation='relu'),# kernel_regularizer=regularizers.l2(0.01)),#  activation='relu',\n",
    "            #tf.keras.layers.LeakyReLU(alpha=0.05), \n",
    "            tf.keras.layers.Dense(128,activation='relu'),\n",
    "            #tf.keras.layers.LeakyReLU(alpha=0.05), \n",
    "            tf.keras.layers.Dense(64,activation='relu'),\n",
    "            #tf.keras.layers.LeakyReLU(alpha=0.05), \n",
    "            tf.keras.layers.Dropout(Dropout1),\n",
    "            tf.keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=\"Adam\",\n",
    "                      loss=keras.losses.binary_crossentropy,\n",
    "                      metrics=['accuracy'])   \n",
    "        checkpoint = ModelCheckpoint(filepath=modelfile, \n",
    "                                     monitor='val_loss',\n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True)#,save_weights_only=True)\n",
    "        cbs = [checkpoint]#, lr_reducer, lr_scheduler]\n",
    "        cbs = [checkpoint]#, lr_reducer, lr_scheduler]\n",
    "        history = model.fit(X_train, \n",
    "                            Y_train, \n",
    "                            epochs= Epochs , \n",
    "                            batch_size= Batch_size, \n",
    "                            verbose=0,\n",
    "                            validation_data=(X_test, Y_test),\n",
    "                            shuffle=False,\n",
    "                            callbacks=cbs)\n",
    "        return history\n",
    "        del model\n",
    "\n",
    "    for model_number in range(1,2):\n",
    "        modelfile = save_model_path+'FULL_B_ALL_pca18_{}.h5'.format(model_number)\n",
    "        FULL_pca18(modelfile,0.3,50,128,18)\n",
    "\n",
    "    def computing_result(Feature_array,Label_array,model):\n",
    "        X_TEST = Feature_array\n",
    "        Y_TEST = Label_array\n",
    "        model1 = model\n",
    "        Y_PRED = model1.predict(X_TEST)\n",
    "        Y_pred2 = np.argmin(Y_PRED, axis=-1)\n",
    "        Y_test2 = np.argmax(Y_TEST, axis=-1)\n",
    "        test=pd.read_csv(test_seq_path)\n",
    "        df = pd.DataFrame({'Class':test.Epitope,'CDR3B':test.CDR3B,'y_prob':Y_PRED[:, 0],'y_pred': Y_pred2, 'y_true': Y_test2})\n",
    "        df.to_csv(result_path+\"FULL_pca18_probability.csv\", index=False)\n",
    "\n",
    "\n",
    "        confusion_matrix1 =confusion_matrix(Y_test2,Y_pred2)\n",
    "        new_confusion_matrix1 = [[confusion_matrix1[1,1],confusion_matrix1[1,0]],[confusion_matrix1[0,1],confusion_matrix1[0,0]]]\n",
    "        accuracy = accuracy_score(Y_test2,Y_pred2) \n",
    "        precision = precision_score(Y_test2,Y_pred2) \n",
    "        recall = recall_score(Y_test2,Y_pred2) \n",
    "        f1= f1_score(Y_test2,Y_pred2) #F1\n",
    "        MCC = matthews_corrcoef(Y_test2,Y_pred2) #MCC\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y_TEST[:,1], Y_PRED[:,1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        return new_confusion_matrix1,accuracy,precision,recall,f1,MCC,fpr,tpr,roc_auc\n",
    "\n",
    "\n",
    "    fileHeader =['model_number','dataset','TP','FN','FP','TN','ACC','precision','recall','f1','MCC','AUC']\n",
    "    csvFile = open(result_path+\"FULL_B_ALL_pca18_result.csv\", \"w\" , newline='')\n",
    "    csv_writer = csv.writer(csvFile)\n",
    "    csv_writer.writerow(fileHeader)\n",
    "    PCA_num = 18\n",
    "    for model_number in range(1,2):\n",
    "        modelfile = save_model_path+'FULL_B_ALL_pca18_{}.h5'.format(model_number)\n",
    "        model = load_model(modelfile)\n",
    "        test_Feature = np.load(testfile_path+\"test_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "        test_Label = np.load(testfile_path+\"test_TCRB_PCA{}_label_array.npy\".format(PCA_num)) \n",
    "        X_test = test_Feature\n",
    "        Y_test = test_Label\n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        test_CM,accuracy1,precision1,recall1,f11,MCC1,fpr1,tpr1,roc_auc1 = computing_result(X_test,Y_test,model)\n",
    "        test_row = [model_number,'TEST',\n",
    "                    test_CM[0][0],test_CM[0][1],\n",
    "                    test_CM[1][0],test_CM[1][1],\n",
    "                    accuracy1,precision1,recall1,f11,MCC1,roc_auc1]\n",
    "        csv_writer.writerow(test_row)   \n",
    "        del model\n",
    "    csvFile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc76012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43145dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62819744",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=['healthy', 'patient']\n",
    "name =['1_1','1_2','1_4','1_6','1_8']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            trainfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            testfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/'+j+'/'+k+'_'+'1_1test.csv'\n",
    "            save_model_path= \"./model/Retrain/pair50/\"+j + '/'+k+'_'+i\n",
    "            result_path  = \"./result/pair50/seen/test/\"+ j + '/'+k+'_'+i\n",
    "            FULL_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)\n",
    "        \n",
    "        \n",
    "database=['Antigen_specificity']\n",
    "name =['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "         for k in name1:\n",
    "            trainfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            testfile_path =\"./data/repeat10/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/'+j+'/'+k+'_'+'1_1test.csv'\n",
    "            save_model_path= \"./model/Retrain/pair50/\"+j + '/' +k+'_'+i\n",
    "            result_path  = \"./result/pair50/seen/test/\"+ j + '/' +k+'_'+i\n",
    "            FULL_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)\n",
    "            \n",
    "            \n",
    "import pandas as pd\n",
    "database=['healthy', 'patient','Antigen_specificity']\n",
    "name=['1_1']\n",
    "pair=['more300','300','200','100','10']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in pair:\n",
    "            for l in name1:\n",
    "                trainfile_path =\"./data/pair300/\"+k+'/'+j + '/' +l+'_1_1'\n",
    "                testfile_path =\"./data/pair300/more300/\"+j + '/' +l+'_1_1' \n",
    "                test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/more300'+'/'+j+'/'+l+'_'+'1_1test.csv'\n",
    "                save_model_path= \"./model/Retrain/pair300/\"+k+'/'+j + '/'  +l+'_1_1'\n",
    "                result_path  = \"./result/Retrain/pair300/seen/\"+k+'/'+j + '/' +l+'_1_1' \n",
    "                FULL_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1da77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e120120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6d1def",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "178de457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/DLpTCR/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ce8ff20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "import time\n",
    "import pandas as pd\n",
    "def validation_main(testfile_path,modelfile_path,test_seq_path,result_path):\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    from tensorflow.python.keras.models import load_model\n",
    "    import numpy as np\n",
    "    model_number=1\n",
    "    PCA_num=18\n",
    "    modelfile = modelfile_path+'FULL_B_ALL_pca18_{}.h5'.format(model_number)\n",
    "    model = load_model(modelfile)\n",
    "    X_TEST = np.load(testfile_path+\"_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "    Y_TEST = np.load(testfile_path+\"_TCRB_PCA{}_label_array.npy\".format(PCA_num))   \n",
    "    X_TEST = X_TEST.reshape([len(X_TEST),20,PCA_num+1,2])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    Y_PRED = model.predict(X_TEST)\n",
    "    Y_pred2 = np.argmin(Y_PRED, axis=-1) \n",
    "    Y_test2 = np.argmax(Y_TEST, axis=-1)\n",
    "    test=pd.read_csv(test_seq_path)\n",
    "    df = pd.DataFrame({'Class':test.Epitope,'CDR3B':test.CDR3B,'y_prob':Y_PRED[:, 0],'y_pred': Y_pred2, 'y_true': Y_test2})\n",
    "    df.to_csv(result_path+\"FULL_pca18_probability.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/seen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+j+\"/\"+k+\"_1_1Validation.csv\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/seen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+j+\"/\"+k+\"_1_1Validation.csv\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b12c498",
   "metadata": {},
   "source": [
    "# unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09a53990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/test/\"+j+\"/\"+k+'_1_1test'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+j+\"/\"+k+\"_1_1test.csv\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/test/\"+j+\"/\"+k+\"_1_1test\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+j+\"/\"+k+\"_1_1test.csv\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  \n",
    "            \n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+j+\"/\"+k+\"_1_1validation.csv\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/validation/\"+j+\"/\"+k+\"_1_1validation\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+j+\"/\"+k+\"_1_1validation.csv\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba917d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718e2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3c54d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebab05d4",
   "metadata": {},
   "source": [
    "# RESNET_pca10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1b5055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path):\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    try:\n",
    "        import tensorflow.python.keras as keras\n",
    "    except:\n",
    "        import tensorflow.keras as keras\n",
    "    from tensorflow.python.keras import layers\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import accuracy_score,matthews_corrcoef,classification_report,confusion_matrix,precision_score,recall_score\n",
    "    from sklearn.metrics import f1_score,roc_auc_score, auc\n",
    "    from keras import regularizers\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    from tensorflow.python.keras.callbacks import ReduceLROnPlateau,LearningRateScheduler, ModelCheckpoint\n",
    "    from keras.utils import plot_model\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.utils import shuffle\n",
    "    from tensorflow.python.keras.models import load_model\n",
    "    import pandas\n",
    "    from tensorflow.keras import models\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    import matplotlib.pyplot as plt\n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 只显示error和warining信息 3 只显示error信息\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 这一行注释掉就是使用cpu，不注释就是使用gpu\n",
    "    def RESNET_pca10(model_number,modelfile,Epochs= 20,Batch_size=32,PCA_num = 10):\n",
    "        train_Feature = np.load(trainfile_path+\"train_TCRB_PCA{}_feature_array.npy\".format(PCA_num))    \n",
    "        train_Label = np.load(trainfile_path+\"train_TCRB_PCA{}_label_array.npy\".format(PCA_num))\n",
    "        test_Feature = np.load(testfile_path+\"test_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "        test_Label = np.load(testfile_path+\"test_TCRB_PCA{}_label_array.npy\".format(PCA_num))   \n",
    "        X_train = train_Feature\n",
    "        Y_train = train_Label#[:,1]  \n",
    "        X_test = test_Feature\n",
    "        Y_test = test_Label#[:,1]  \n",
    "        X_train,Y_train = shuffle(X_train,Y_train)\n",
    "        X_test,Y_test = shuffle(X_test,Y_test)\n",
    "        modelfile = modelfile\n",
    "        model_number = model_number\n",
    "        X_train= X_train.reshape([len(X_train),20,PCA_num+1,2])    \n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        X_test=tf.cast(X_test, tf.float32)\n",
    "        Epochs = Epochs\n",
    "        Batch_size = Batch_size\n",
    "        resnet_attention_train_predict(20, PCA_num ,model_number,modelfile,2,X_train,Y_train,X_test,Y_test,Epochs,Batch_size)\n",
    "    def lr_schedule(epoch):\n",
    "        lr = 1e-3\n",
    "        return lr*0.9*epoch\n",
    "    def resnet_layer(inputs, num_filters, kernel_size=3, strides=1,\n",
    "                     activation='relu', batch_normalization=True, conv_first=True):\n",
    "        conv = layers.Conv2D(num_filters, kernel_size=kernel_size, strides=strides,\n",
    "                             padding='same', kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=l2(1e-4))\n",
    "        x = inputs\n",
    "        if conv_first:\n",
    "            x = conv(x)\n",
    "            if batch_normalization:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            if activation is not None:\n",
    "                x = layers.Activation(activation)(x)\n",
    "        else:\n",
    "            if batch_normalization:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            if activation is not None:\n",
    "                x = layers.Activation(activation)(x)\n",
    "            x = conv(x)\n",
    "        return x\n",
    "\n",
    "    def resnet_v1(input_shape, depth, num_classes=2):\n",
    "        if (depth-2)%6 != 0:\n",
    "            raise ValueError('depth should be 6n+2')\n",
    "        # Start model definition.\n",
    "        num_filters = 32\n",
    "        num_res_blocks = int((depth-2)/6)\n",
    "        inputs = tf.keras.Input(shape=input_shape)\n",
    "        x = resnet_layer(inputs, num_filters)\n",
    "        # Instantiate teh stack of residual units\n",
    "        for stack in range(3):\n",
    "            for res_block in range(num_res_blocks):\n",
    "                strides = 1\n",
    "                if stack > 0 and res_block == 0: # first layer but not first stack\n",
    "                    strides = 2 # downsample\n",
    "                y = resnet_layer(x, num_filters, strides=strides)  \n",
    "                y = resnet_layer(y, num_filters, activation=None)\n",
    "\n",
    "                if stack > 0 and res_block == 0: # first layer but not first stack\n",
    "                    # linear projection residual shortcut connection to match\n",
    "                    # change dims\n",
    "                    x = resnet_layer(x, num_filters, kernel_size=1, strides=strides,\n",
    "                                     activation=None, batch_normalization=False)\n",
    "                x = layers.add([x, y])\n",
    "                x = layers.Activation('relu')(x)           \n",
    "            num_filters *= 2\n",
    "        ax = layers.GlobalAveragePooling2D()(x)\n",
    "        ax = layers.Dense(num_filters//8, activation='relu')(ax)\n",
    "        ax = layers.Dense(num_filters//2, activation='softmax')(ax)\n",
    "        ax = layers.Reshape((1,1,num_filters//2))(ax)\n",
    "        ax = layers.Multiply()([ax, x])\n",
    "        y = layers.Flatten()(ax)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax',\n",
    "                               kernel_initializer='he_normal')(y)\n",
    "        # Instantiate model\n",
    "        model = models.Model(inputs=inputs, outputs=outputs)\n",
    "        return model   \n",
    "    def resnet_attention_train_predict(row, PCA_num,model_number, modelfile, m, x_train, y_train,x_test, y_test,Epochs,Batch_size):\n",
    "        y_train, y_train,x_test, y_test = x_train, y_train,x_test, y_test\n",
    "        model = resnet_v1(input_shape=(row, PCA_num+1, m), depth=20, num_classes=2)\n",
    "        model.compile(optimizer=\"Adam\",\n",
    "                  loss=keras.losses.binary_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "        lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5,\n",
    "                                       min_lr=0.5e-6)\n",
    "        checkpoint = ModelCheckpoint(filepath=modelfile, monitor='val_loss',\n",
    "                                    verbose=0, save_best_only=True)#,save_weights_only=True)\n",
    "        cbs = [checkpoint, lr_reducer, lr_scheduler]\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=Batch_size,\n",
    "                      epochs=Epochs,\n",
    "                      verbose=0, \n",
    "                      validation_data=(x_test, y_test),\n",
    "                      shuffle=False,\n",
    "                      callbacks=cbs)#callbacks=cbs\n",
    "        del model\n",
    "    def computing_result(Feature_array,Label_array,model):\n",
    "        X_TEST = Feature_array\n",
    "        Y_TEST = Label_array\n",
    "        K.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        model1 = model\n",
    "        Y_PRED = model1.predict(X_TEST)\n",
    "        Y_pred2 = np.argmin(Y_PRED, axis=-1)\n",
    "        Y_test2 = np.argmax(Y_TEST, axis=-1)\n",
    "        test=pd.read_csv(test_seq_path)\n",
    "        df = pd.DataFrame({'Class':test.Epitope,'CDR3B':test.CDR3B,'y_prob':Y_PRED[:, 0],'y_pred': Y_pred2, 'y_true': Y_test2})\n",
    "        df.to_csv(result_path+\"RESNET_pca10_probability.csv\", index=False)\n",
    "\n",
    "        confusion_matrix1 =confusion_matrix(Y_test2,Y_pred2)\n",
    "        new_confusion_matrix1 = [[confusion_matrix1[1,1],confusion_matrix1[1,0]],[confusion_matrix1[0,1],confusion_matrix1[0,0]]]\n",
    "        accuracy = accuracy_score(Y_test2,Y_pred2) \n",
    "        precision = precision_score(Y_test2,Y_pred2)\n",
    "        recall = recall_score(Y_test2,Y_pred2) \n",
    "        f1= f1_score(Y_test2,Y_pred2) \n",
    "        MCC = matthews_corrcoef(Y_test2,Y_pred2) \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y_TEST[:,1], Y_PRED[:,1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        return new_confusion_matrix1,accuracy,precision,recall,f1,MCC,fpr,tpr,roc_auc\n",
    "\n",
    "        K.clear_session()\n",
    "        tf.reset_default_graph()\n",
    "        model = load_model(modelfile)\n",
    "        X_test = np.load(test_Feature_path)\n",
    "        Y_test = np.load(test_Label_path)\n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        test_CM,accuracy1,precision1,recall1,f11,MCC1,fpr1,tpr1,roc_auc1 = computing_result(X_test,Y_test,model)\n",
    "        test_row = [model_number,'TEST',\n",
    "                    test_CM[0][0],test_CM[0][1],\n",
    "                    test_CM[1][0],test_CM[1][1],\n",
    "                    accuracy1,precision1,recall1,f11,MCC1,roc_auc1]\n",
    "        del model\n",
    "        return test_row,X_test_original\n",
    "    PCA_num=10\n",
    "    for model_number in range(1,2):\n",
    "        modelfile =save_model_path+'RESNET_B_ALL_test_pca10_{}.h5'.format(model_number)\n",
    "        RESNET_pca10(model_number,modelfile,20,32,10)\n",
    "    fileHeader =['model_number','dataset','TP','FN','FP','TN','ACC','precision','recall','f1','MCC','AUC']\n",
    "    csvFile = open(result_path+\"RESNET_pca10_result.csv\", \"w\" , newline='')\n",
    "    csv_writer = csv.writer(csvFile)\n",
    "    csv_writer.writerow(fileHeader)\n",
    "    for model_number in range(1,2):\n",
    "        modelfile = save_model_path+'RESNET_B_ALL_test_pca10_{}.h5'.format(model_number)\n",
    "        model = load_model(modelfile)\n",
    "        test_Feature = np.load(testfile_path+\"test_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "        test_Label = np.load(testfile_path+\"test_TCRB_PCA{}_label_array.npy\".format(PCA_num))   \n",
    "        X_test = test_Feature\n",
    "        Y_test = test_Label\n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        test_CM,accuracy1,precision1,recall1,f11,MCC1,fpr1,tpr1,roc_auc1 = computing_result(X_test,Y_test,model)\n",
    "        test_row = [model_number,'TEST',\n",
    "                    test_CM[0][0],test_CM[0][1],\n",
    "                    test_CM[1][0],test_CM[1][1],\n",
    "                    accuracy1,precision1,recall1,f11,MCC1,roc_auc1]\n",
    "        csv_writer.writerow(test_row)    \n",
    "        del model\n",
    "    csvFile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580bbd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=['healthy', 'patient']\n",
    "name =['1_1','1_2','1_4','1_6','1_8']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            trainfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            testfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/'+j+'/'+k+'_'+'1_1test.csv'\n",
    "            save_model_path= \"./model/Retrain/pair50/\"+j + '/'+k+'_'+i\n",
    "            result_path  = \"./result/pair50/seen/test/\"+ j + '/'+k+'_'+i\n",
    "            train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)\n",
    "        \n",
    "        \n",
    "database=['Antigen_specificity']\n",
    "name =['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "         for k in name1:\n",
    "            trainfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            testfile_path =\"./data/repeat10/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/'+j+'/'+k+'_'+'1_1test.csv'\n",
    "            save_model_path= \"./model/Retrain/pair50/\"+j + '/' +k+'_'+i\n",
    "            result_path  = \"./result/pair50/seen/test/\"+ j + '/' +k+'_'+i\n",
    "            train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)\n",
    "            \n",
    "            \n",
    "import pandas as pd\n",
    "database=['healthy', 'patient','Antigen_specificity']\n",
    "name=['1_1']\n",
    "pair=['more300','300','200','100','10']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in pair:\n",
    "            for l in name1:\n",
    "                trainfile_path =\"./data/pair300/\"+k+'/'+j + '/' +l+'_1_1'\n",
    "                testfile_path =\"./data/pair300/more300/\"+j + '/' +l+'_1_1' \n",
    "                test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/more300'+'/'+j+'/'+l+'_'+'1_1test.csv'\n",
    "                save_model_path= \"./model/Retrain/pair300/\"+k+'/'+j + '/'  +l+'_1_1'\n",
    "                result_path  = \"./result/Retrain/pair300/seen/\"+k+'/'+j + '/' +l+'_1_1' \n",
    "                train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d360120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4101520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def validation_main(testfile_path,modelfile_path,test_seq_path,result_path):\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    from tensorflow.python.keras.models import load_model\n",
    "    import numpy as np\n",
    "    model_number=1\n",
    "    PCA_num=10\n",
    "    modelfile = modelfile_path+ 'RESNET_B_ALL_test_pca10_{}.h5'.format(model_number)\n",
    "    model = load_model(modelfile)\n",
    "    X_TEST = np.load(testfile_path+\"_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "    Y_TEST = np.load(testfile_path+\"_TCRB_PCA{}_label_array.npy\".format(PCA_num))   \n",
    "    X_TEST = X_TEST.reshape([len(X_TEST),20,PCA_num+1,2])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    Y_PRED = model.predict(X_TEST)\n",
    "    Y_pred2 = np.argmin(Y_PRED, axis=-1) \n",
    "    Y_test2 = np.argmax(Y_TEST, axis=-1)\n",
    "    test=pd.read_csv(test_seq_path)\n",
    "    df = pd.DataFrame({'Class':test.Epitope,'CDR3B':test.CDR3B,'y_prob':Y_PRED[:, 0],'y_pred': Y_pred2, 'y_true': Y_test2})\n",
    "    df.to_csv(result_path+\"RESNET_pca10_probability.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6dbaae5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/seen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+j+\"/\"+k+\"_1_1Validation.csv\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/seen/validation/\"+j+\"/\"+k+\"_1_1validation\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+j+\"/\"+k+\"_1_1Validation.csv\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  \n",
    "            \n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/test/\"+j+\"/\"+k+'_1_1test'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+j+\"/\"+k+\"_1_1test.csv\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/test/\"+j+\"/\"+k+\"_1_1test\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+j+\"/\"+k+\"_1_1test.csv\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  \n",
    "            \n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+j+\"/\"+k+\"_1_1validation.csv\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/validation/\"+j+\"/\"+k+\"_1_1validation\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+j+\"/\"+k+\"_1_1validation.csv\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f32a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbda543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2f77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c03a6ff",
   "metadata": {},
   "source": [
    "# CNN PCA 20pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28ee4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path):\n",
    "    #!/usr/bin/env python\n",
    "    # coding: utf-8\n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        import tensorflow.python.keras as keras\n",
    "    except:\n",
    "        import tensorflow.keras as keras\n",
    "    from tensorflow.python.keras import layers\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import accuracy_score,matthews_corrcoef,classification_report,confusion_matrix,precision_score,recall_score\n",
    "    from sklearn.metrics import f1_score,roc_auc_score, auc\n",
    "    from keras import regularizers\n",
    "    import os\n",
    "    import scipy.io as sio\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    from tensorflow.python.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "    from keras.utils import plot_model\n",
    "    #from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.utils import shuffle\n",
    "    from tensorflow.python.keras.models import load_model\n",
    "    import matplotlib.pyplot as plt\n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "    def CNN_pca20(modelfile,Dropout1=0,Epochs= 20,Batch_size=64,PCA_num = 20):\n",
    "        train_Feature = np.load(trainfile_path+\"train_TCRB_PCA{}_feature_array.npy\".format(PCA_num))    \n",
    "        train_Label = np.load(trainfile_path+\"train_TCRB_PCA{}_label_array.npy\".format(PCA_num))\n",
    "        test_Feature = np.load(testfile_path+\"test_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "        test_Label = np.load(testfile_path+\"test_TCRB_PCA{}_label_array.npy\".format(PCA_num))          \n",
    "        X_train = train_Feature\n",
    "        Y_train = train_Label  \n",
    "        X_test = test_Feature\n",
    "        Y_test = test_Label\n",
    "        X_train,Y_train = shuffle(X_train,Y_train)\n",
    "        X_test,Y_test = shuffle(X_test,Y_test)\n",
    "        X_train= X_train.reshape([len(X_train),20,PCA_num+1,2])\n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        X_test=tf.cast(X_test, tf.float32)\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, (5,5),padding = 'same', input_shape=(20,PCA_num+1,2),activation='relu'),            \n",
    "            tf.keras.layers.AveragePooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(128, (3,3),padding = 'same',activation='relu'),\n",
    "            tf.keras.layers.AveragePooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512,activation='relu'),# kernel_regularizer=regularizers.l2(0.01)),#  activation='relu',\n",
    "            tf.keras.layers.Dense(256,activation='relu'),# kernel_regularizer=regularizers.l2(0.01)),#  activation='relu',\n",
    "            tf.keras.layers.Dense(128,activation='relu'),\n",
    "            tf.keras.layers.Dense(64,activation='relu'),\n",
    "            tf.keras.layers.Dropout(Dropout1),\n",
    "            tf.keras.layers.Dense(2, activation='softmax')\n",
    "        ]) \n",
    "        model.compile(optimizer=\"Adam\",\n",
    "                      loss=keras.losses.binary_crossentropy,\n",
    "                      metrics=['accuracy'])   \n",
    "        checkpoint = ModelCheckpoint(filepath=modelfile, \n",
    "                                     monitor='val_loss',\n",
    "                                     verbose=0, \n",
    "                                     save_best_only=True)#,save_weights_only=True)\n",
    "        cbs = [checkpoint]#, lr_reducer, lr_scheduler]\n",
    "        history = model.fit(X_train, \n",
    "                            Y_train, \n",
    "                            epochs= Epochs , \n",
    "                            batch_size= Batch_size, \n",
    "                            verbose=0,\n",
    "                            validation_data=(X_test, Y_test),\n",
    "                            shuffle=False,\n",
    "                            callbacks=cbs)\n",
    "        return history\n",
    "        del model\n",
    "\n",
    "    for model_number in range(1,2):\n",
    "        print(model_number)\n",
    "        modelfile =save_model_path+'CNN_B_ALL_pca20_plt_{}.h5'.format(model_number)\n",
    "        history = CNN_pca20(modelfile,0.3,300,128,20)\n",
    "        test_row = history.history['val_accuracy']\n",
    "\n",
    "    def computing_result(Feature_array,Label_array,model):\n",
    "        X_TEST = Feature_array\n",
    "        Y_TEST = Label_array\n",
    "        model1 = model\n",
    "        Y_PRED = model1.predict(X_TEST)\n",
    "        Y_pred2 = np.argmin(Y_PRED, axis=-1) \n",
    "        Y_test2 = np.argmax(Y_TEST, axis=-1)\n",
    "        test=pd.read_csv(test_seq_path)\n",
    "        df = pd.DataFrame({'Class':test.Epitope,'CDR3B':test.CDR3B,'y_prob':Y_PRED[:, 0],'y_pred': Y_pred2, 'y_true': Y_test2})\n",
    "        df.to_csv(result_path+\"CNN_pca20_probability.csv\", index=False)\n",
    "\n",
    "        confusion_matrix1 =confusion_matrix(Y_test2,Y_pred2)\n",
    "        new_confusion_matrix1 = [[confusion_matrix1[1,1],confusion_matrix1[1,0]],[confusion_matrix1[0,1],confusion_matrix1[0,0]]]\n",
    "        accuracy = accuracy_score(Y_test2,Y_pred2) \n",
    "        precision = precision_score(Y_test2,Y_pred2) \n",
    "        recall = recall_score(Y_test2,Y_pred2)\n",
    "        f1= f1_score(Y_test2,Y_pred2) \n",
    "        MCC = matthews_corrcoef(Y_test2,Y_pred2) \n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y_TEST[:,1], Y_PRED[:,1])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        return new_confusion_matrix1,accuracy,precision,recall,f1,MCC,fpr,tpr,roc_auc  \n",
    "    fileHeader =['model_number','dataset','TP','FN','FP','TN','ACC','precision','recall','f1','MCC','AUC']\n",
    "\n",
    "    csvFile = open(result_path+\"CNN_pca20_result.csv\", \"w\" , newline='')\n",
    "    csv_writer = csv.writer(csvFile)\n",
    "    csv_writer.writerow(fileHeader)\n",
    "    PCA_num = 20\n",
    "    for model_number in range(1,2):\n",
    "        modelfile =save_model_path+'CNN_B_ALL_pca20_plt_{}.h5'.format(model_number)\n",
    "        model = load_model(modelfile)\n",
    "        test_Feature = np.load(testfile_path+\"test_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "        test_Label = np.load(testfile_path+\"test_TCRB_PCA{}_label_array.npy\".format(PCA_num))\n",
    "        X_test = test_Feature\n",
    "        Y_test = test_Label\n",
    "        X_test = X_test.reshape([len(X_test),20,PCA_num+1,2])\n",
    "        test_CM,accuracy1,precision1,recall1,f11,MCC1,fpr1,tpr1,roc_auc1 = computing_result(X_test,Y_test,model)\n",
    "        test_row = [model_number,'TEST',\n",
    "                    test_CM[0][0],test_CM[0][1],\n",
    "                    test_CM[1][0],test_CM[1][1],\n",
    "                    accuracy1,precision1,recall1,f11,MCC1,roc_auc1]\n",
    "        csv_writer.writerow(test_row)\n",
    "        del model\n",
    "    csvFile.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=['healthy', 'patient']\n",
    "name =['1_1','1_2','1_4','1_6','1_8']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            trainfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            testfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/'+j+'/'+k+'_'+'1_1test.csv'\n",
    "            save_model_path= \"./model/Retrain/pair50/\"+j + '/'+k+'_'+i\n",
    "            result_path  = \"./result/pair50/seen/test/\"+ j + '/'+k+'_'+i\n",
    "            CNN_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)\n",
    "        \n",
    "        \n",
    "database=['Antigen_specificity']\n",
    "name =['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "         for k in name1:\n",
    "            trainfile_path =\"./data/pair50/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            testfile_path =\"./data/repeat10/seen/test/\"+j + '/' +k+'_1_1'\n",
    "            test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair50/'+j+'/'+k+'_'+'1_1test.csv'\n",
    "            save_model_path= \"./model/Retrain/pair50/\"+j + '/' +k+'_'+i\n",
    "            result_path  = \"./result/pair50/seen/test/\"+ j + '/' +k+'_'+i\n",
    "            CNN_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)\n",
    "            \n",
    "            \n",
    "import pandas as pd\n",
    "database=['healthy', 'patient','Antigen_specificity']\n",
    "name=['1_1']\n",
    "pair=['more300','300','200','100','10']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in pair:\n",
    "            for l in name1:\n",
    "                trainfile_path =\"./data/pair300/\"+k+'/'+j + '/' +l+'_1_1'\n",
    "                testfile_path =\"./data/pair300/more300/\"+j + '/' +l+'_1_1' \n",
    "                test_seq_path='/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/pair300/more300'+'/'+j+'/'+l+'_'+'1_1test.csv'\n",
    "                save_model_path= \"./model/Retrain/pair300/\"+k+'/'+j + '/'  +l+'_1_1'\n",
    "                result_path  = \"./result/Retrain/pair300/seen/\"+k+'/'+j + '/' +l+'_1_1' \n",
    "                CNN_train_main(trainfile_path,testfile_path,test_seq_path,save_model_path,result_path)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff5ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6ef2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def validation_main(testfile_path,modelfile_path,test_seq_path,result_path):\n",
    "    from tensorflow.python.keras import backend as K\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    from tensorflow.python.keras.models import load_model\n",
    "    import numpy as np\n",
    "    model_number=1\n",
    "    PCA_num=20\n",
    "    modelfile = modelfile_path+ 'CNN_B_ALL_pca20_plt_{}.h5'.format(model_number)\n",
    "    model = load_model(modelfile)\n",
    "    X_TEST = np.load(testfile_path+\"_TCRB_PCA{}_feature_array.npy\".format(PCA_num)) \n",
    "    Y_TEST = np.load(testfile_path+\"_TCRB_PCA{}_label_array.npy\".format(PCA_num))   \n",
    "    X_TEST = X_TEST.reshape([len(X_TEST),20,PCA_num+1,2])\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    Y_PRED = model.predict(X_TEST)\n",
    "    Y_pred2 = np.argmin(Y_PRED, axis=-1) \n",
    "    Y_test2 = np.argmax(Y_TEST, axis=-1)\n",
    "    test=pd.read_csv(test_seq_path)\n",
    "    df = pd.DataFrame({'Class':test.Epitope,'CDR3B':test.CDR3B,'y_prob':Y_PRED[:, 0],'y_pred': Y_pred2, 'y_true': Y_test2})\n",
    "    df.to_csv(result_path+\"CNN_pca20_probability.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d668dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/seen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+j+\"/\"+k+\"_1_1Validation.csv\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/seen/validation/\"+j+\"/\"+k+\"_1_1validation\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/Validation/\"+j+\"/\"+k+\"_1_1Validation.csv\"\n",
    "            result_path=\"./result/pair50/seen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path) \n",
    "            \n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/test/\"+j+\"/\"+k+'_1_1test'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+j+\"/\"+k+\"_1_1test.csv\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/test/\"+j+\"/\"+k+\"_1_1test\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/\"+j+\"/\"+k+\"_1_1test.csv\"\n",
    "            result_path=\"./result/pair50/unseen/test/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  \n",
    "            \n",
    "name=['1_1','1_2','1_4','1_6','1_8']\n",
    "database=['healthy', 'patient']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/validation/\"+j+\"/\"+k+'_1_1validation'\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+j+\"/\"+k+\"_1_1validation.csv\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)\n",
    "        \n",
    "\n",
    "database=['Antigen_specificity']\n",
    "name=['1_1','1_2','1_4']\n",
    "name1=['1','2','3','4','5']\n",
    "for i in name:\n",
    "    for j in database:\n",
    "        for k in name1:\n",
    "            testfile_path=\"./data/pair50/unseen/validation/\"+j+\"/\"+k+\"_1_1validation\"\n",
    "            modelfile_path=\"./model/Retrain/pair50/\"+j+\"/\"+k+'_'+i\n",
    "            test_seq_path= \"/home/luyanping/data/TCR_epitope_prediction/Compare_models_same_data/database/benchmark_dataset/10cross_validation/unknow/validation/\"+j+\"/\"+k+\"_1_1validation.csv\"\n",
    "            result_path=\"./result/pair50/unseen/validation/\"+j+\"/\"+k+'_'+i\n",
    "            validation_main(testfile_path,modelfile_path,test_seq_path,result_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8b7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e7753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016aec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf649383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e080a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be4bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dcdd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c4ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d78d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb24522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae042c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLpTCR",
   "language": "python",
   "name": "dlptcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
